{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d615f90b",
   "metadata": {},
   "source": [
    "# Model Training\n",
    "Trains a model on past data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a94b2d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d154e01b-69f9-4b2e-adf2-34a7b8833a66",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e88ece4",
   "metadata": {},
   "source": [
    "### SET PARAMETERS:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "id": "ff649bbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "TICKER=\"TSLA\"\n",
    "DATA_INTERVAL_MINUTES = 15   # (Set to 5 or 15)\n",
    "DATA_AFTER_HOURS = False\n",
    "\n",
    "DAYS_PREDICT = 15\n",
    "# ISSUE: If stock goes down slowly, less than 'DOWN_PCTS_PREDICT' then won't sell but after few periods will be very down \n",
    "#  example: DOWN_PCTS_PREDICT=5% then down 4% and down 3% and down 1%... and never sell\n",
    "DOWN_PCTS_PREDICT= [5.0]\n",
    "UP_PCTS_PREDICT= [7.0]\n",
    "\n",
    "signal_avg= [\n",
    "    2, \n",
    "    3, \n",
    "    5, \n",
    "    8, \n",
    "    13, \n",
    "    21, \n",
    "    34, \n",
    "    55, \n",
    "    89, \n",
    "    144, \n",
    "    233, \n",
    "    377, \n",
    "    610, \n",
    "    987, \n",
    "    1597, \n",
    "    2584]\n",
    "\n",
    "PREDICT_UP = True\n",
    "if PREDICT_UP:\n",
    "    INDEX_KEEP= 2\n",
    "    INDEX_REMOVE_A= 0\n",
    "    INDEX_REMOVE_B= 1\n",
    "else:\n",
    "    INDEX_KEEP= 0\n",
    "    INDEX_REMOVE_A= 1\n",
    "    INDEX_REMOVE_B= 2\n",
    "\n",
    "TRAIN_SPLIT = 0.9\n",
    "\n",
    "# TODO: When executing only using 33-38% GPU - Try different BATCH_SIZE see if parallelism increases? Learning decreases because less batches?\n",
    "BATCH_SIZE= 32\n",
    "\n",
    "HIDDEN_UNITS=12\n",
    "\n",
    "TRAINING_THRESHOLD = 0.7"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a7064ba",
   "metadata": {},
   "source": [
    "#### DOWNLOAD DATA (DON'T EXECUTE IF ALREADY LOADED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62afeeba-6a9c-41cf-bbf7-da672fc6ff5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..\\\\..')\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "import settings\n",
    "import apis.tiingo_api as tiingo\n",
    "\n",
    "secret_key= settings.get_secret(\"tiingo-key\")\n",
    "\n",
    "### TRAINING DATA\n",
    "csv_data2017= tiingo.download_ticker(secret_key, TICKER, datetime(2017, 1, 1), datetime(2018,1,1), DATA_INTERVAL_MINUTES, DATA_AFTER_HOURS)\n",
    "csv_data2018= tiingo.download_ticker(secret_key, TICKER, datetime(2018, 1, 1), datetime(2019,1,1), DATA_INTERVAL_MINUTES, DATA_AFTER_HOURS)\n",
    "csv_data2019= tiingo.download_ticker(secret_key, TICKER, datetime(2019, 1, 1), datetime(2020,1,1), DATA_INTERVAL_MINUTES, DATA_AFTER_HOURS)\n",
    "csv_data2020= tiingo.download_ticker(secret_key, TICKER, datetime(2020, 1, 1), datetime(2021,1,1), DATA_INTERVAL_MINUTES, DATA_AFTER_HOURS)\n",
    "csv_data2021= tiingo.download_ticker(secret_key, TICKER, datetime(2021, 1, 1), datetime(2022,1,1), DATA_INTERVAL_MINUTES, DATA_AFTER_HOURS)\n",
    "csv_data2022= tiingo.download_ticker(secret_key, TICKER, datetime(2022, 1, 1), datetime(2023,1,1), DATA_INTERVAL_MINUTES, DATA_AFTER_HOURS)\n",
    "csv_data2023= tiingo.download_ticker(secret_key, TICKER, datetime(2023, 1, 1), datetime(2024,1,1), DATA_INTERVAL_MINUTES, DATA_AFTER_HOURS)\n",
    "# csv_data2024= tiingo.download_ticker(secret_key, TICKER, datetime(2024, 1, 1), datetime(2024,2,1), DATA_INTERVAL_MINUTES, DATA_AFTER_HOURS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47a77e70-8b1d-4be0-9330-cfe1fe98ddaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "import pandas as pd\n",
    "\n",
    "# ### TRAINING DATA\n",
    "df2017 = pd.read_csv(io.StringIO(csv_data2017))\n",
    "df2018 = pd.read_csv(io.StringIO(csv_data2018))\n",
    "df2019 = pd.read_csv(io.StringIO(csv_data2019))\n",
    "df2020 = pd.read_csv(io.StringIO(csv_data2020))\n",
    "df2021 = pd.read_csv(io.StringIO(csv_data2021))\n",
    "df2022 = pd.read_csv(io.StringIO(csv_data2022))\n",
    "df2023 = pd.read_csv(io.StringIO(csv_data2023))\n",
    "# df2024 = pd.read_csv(io.StringIO(csv_data2024))\n",
    "\n",
    "if not df2017.empty:\n",
    "    print(\"Concatenating from 2017\")\n",
    "    df = pd.concat([df2017, df2018, df2019, df2020, df2021, df2022, df2023], axis=0, ignore_index=True)\n",
    "elif not df2018.empty:\n",
    "    print(\"Concatenating from 2018\")\n",
    "    df = pd.concat([df2018, df2019, df2020, df2021, df2022, df2023], axis=0, ignore_index=True)\n",
    "elif not df2019.empty:\n",
    "    print(\"Concatenating from 2019\")\n",
    "    df = pd.concat([df2019, df2020, df2021, df2022, df2023], axis=0, ignore_index=True)\n",
    "elif not df2020.empty:\n",
    "    print(\"Concatenating from 2020\")\n",
    "    df = pd.concat([df2020, df2021, df2022, df2023], axis=0, ignore_index=True)\n",
    "else:\n",
    "    print(\"Concatenating from 2021\")\n",
    "    df = pd.concat([df2021, df2022, df2023], axis=0, ignore_index=True)\n",
    "\n",
    "# if not df2024.empty:\n",
    "#     print(\"Concatenating from 2024\")\n",
    "#     df = pd.concat([df, df2024], axis=0, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d66b7cc7-98a6-43a0-82b1-0b2abdc83d37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validates that data has been concatenated correctly = ordered ascending\n",
    "if df[\"date\"].is_monotonic_increasing and df[\"date\"].is_unique:\n",
    "    print(\"Correct: DataFrame is in ascending order.\")\n",
    "else:\n",
    "    print(\"Error: DataFrame is not in ascending order.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1de91e28-bd1d-41bf-899b-4e183ae5be45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Displays first and last element in the data\n",
    "print(f\"Data first:\\n{df[['date', 'close']][:5]}\")\n",
    "print(f\"Data last:\\n{df[['date', 'close']][-5:]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "id": "5e990fa6-00fc-496d-be86-955866c3ffb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alpha: 0.0077 for window: 390 and reach: 0.95\n",
      "Check correct 'nan' point (window=390): [1, nan]\n",
      "prices vs input_data: [(309.53, 311.3514908170164), (310.155, 311.3423353428517), (308.87, 311.3234171848216), (309.4, 311.3086993147861), (309.91, 311.29799655362945), (309.975, 311.2878730653465), (313.1, 311.30173934923044), (313.23, 311.3164942811696), (312.45, 311.3251677972356), (312.89, 311.3371417970363), (312.15, 311.34336173802615), (312.31, 311.35075839457227), (312.07, 311.3562619871139), (312.43, 311.3644781643689), (313.37, 311.37982429414416), (313.19, 311.39367564734533), (313.45, 311.4094105148572), (313.0, 311.42158160779894), (313.82, 311.43993415786747), (314.47, 311.46312003538566), (314.87, 311.48918927140033), (315.34, 311.5186554383256), (315.9, 311.55218121752125), (315.29, 311.5807827770222), (315.49, 311.6106958668513), (314.79, 311.63502370659626), (315.81, 311.66697036849183), (316.84, 311.70655407316457), (318.06, 311.7551702507503), (318.2, 311.80448569172637), (319.49, 311.8632947746637), (321.375, 311.9360777582137), (321.63, 312.01025505516975), (321.66, 312.0840943101658), (320.93, 312.15178263660727), (322.81, 312.23333866054344), (322.565, 312.31239589786304), (321.84, 312.38530053864076), (322.235, 312.4606698333029), (322.58, 312.5381023255439), (322.31, 312.6128762857164), (322.035, 312.6849737970518), (321.89, 312.7554100915788), (322.99, 312.83372454427666), (323.6, 312.91610742209133), (323.83, 312.99961985704863), (324.335, 313.0863574889382), (323.73, 313.1678019870005), (324.42, 313.25390311434614), (324.33, 313.33865672669305), (324.71, 313.4256695462448), (324.38, 313.50949140934176), (324.34, 313.59236579515556), (325.15, 313.6808041014612), (325.15, 313.7685656832847), (325.15, 313.8556557188802), (325.15, 313.9420793468781), (325.15, 314.02784166658836), (325.15, 314.1129477383014), (325.15, 314.1974025835865), (325.15, 314.28121118558823), (325.15, 314.3643784893205), (325.15, 314.4469094019582), (325.15, 314.52880879312687), (325.15, 314.61008149518995), (325.15, 314.69073230353393), (325.15, 314.77076597685135), (325.15, 314.8501872374215), (325.15, 314.92900077138904), (325.15, 315.0072112290406), (325.15, 315.084823225079), (325.15, 315.1618413388957), (325.15, 315.23827011484104), (325.15, 315.31411406249214), (325.15, 315.3893776569191), (325.15, 315.4640653389492), (325.15, 315.53818151542856), (325.15, 315.6117305594826), (325.15, 315.6847168107738), (325.15, 315.7571445757577), (330.6, 315.87072119283994), (330.94, 315.98603038772643), (330.96, 316.1006102825138), (331.81, 316.22081756672844), (333.17, 316.35051166857465), (333.11, 316.47875424281705), (332.51, 316.60142434965786), (332.23, 316.7210132495996), (331.97, 316.83769755861834), (332.525, 316.9577358323543), (332.27, 317.07490433627913), (333.46, 317.20028208084807), (333.77, 317.3270725435639), (334.025, 317.454844057776), (334.79, 317.58749160518084), (334.805, 317.7192389207866), (333.98, 317.8436652647597), (334.58, 317.97173066910767), (334.275, 318.09648228360896), (334.02, 318.2183280621054), (333.3, 318.33373208846626), (332.95, 318.4455748718332), (334.43, 318.5678867100996), (334.58, 318.6904104164771), (335.38, 318.81811812979834), (335.065, 318.9424382709175), (338.09, 319.0889542359663), (335.91, 319.21766784389814), (337.04, 319.3540432337372), (336.67, 319.48654387022805), (338.21, 319.6298146053074), (342.54, 319.8051219352977), (340.81, 319.96584997074814), (341.67, 320.1319287922761), (341.405, 320.29470902516687), (341.96, 320.4604904995997), (341.855, 320.62419997083936), (340.45, 320.7759057736584), (338.99, 320.91527890277115), (337.9, 321.04524494428887), (338.41, 321.17811898229024), (337.54, 321.30331908981526), (337.81, 321.4296271972144), (338.33, 321.55894781076927), (336.91, 321.67641311825037), (337.26, 321.795657766901), (339.415, 321.9304798903302), (339.57, 322.06545641363033), (339.18, 322.1964158488527), (340.465, 322.33620593151977), (339.94, 322.47090908134936), (340.965, 322.61242472793583), (341.725, 322.7586729787667), (342.54, 322.9100384768635), (342.22, 323.0577971151511), (340.41, 323.1905751047128), (339.65, 323.3165216119915), (338.26, 323.4308681898056), (340.35, 323.5603323461317), (341.45, 323.69722298305953), (340.69, 323.82725066797957), (341.025, 323.9588467884517), (340.685, 324.0868342844064), (341.6, 324.220843951652), (340.72, 324.347094479271), (340.81, 324.47306762008157), (340.23, 324.5936386978259), (340.34, 324.71412888633336), (340.42, 324.8343092464079), (340.79, 324.9564012110068), (340.39, 325.07449815999377), (340.13, 325.18970193437474), (340.6, 325.3076205876592), (340.86, 325.4266264386727), (340.55, 325.5423495632921), (340.765, 325.65883234845774), (340.51, 325.7724725701922), (340.265, 325.88336849900116), (338.62, 325.98082842012553), (338.59, 326.07731302577037), (341.115, 326.19238048189374), (341.0, 326.3056874759887), (341.58, 326.42256557626985), (341.96, 326.5414570691495), (341.01, 326.65216947004717), (341.76, 326.7677736603461), (341.975, 326.8841384212695), (341.825, 326.99846497541984), (341.31, 327.1079759614725), (341.87, 327.2209340617612), (341.875, 327.33306607330445), (341.56, 327.4419296969578), (341.26, 327.54766472130234), (340.6, 327.64754038832234), (340.07, 327.7425962854667), (339.86, 327.83531791364265), (339.825, 327.9270622237729), (339.75, 328.0175306166944), (339.47, 328.1051642082518), (340.01, 328.19625927975255), (339.57, 328.28329044442097), (339.9, 328.3721807916782), (339.565, 328.45782755606143), (339.715, 328.54396674744675), (336.11, 328.6018615686921), (337.27, 328.66818963100144), (337.055, 328.7323649882757), (338.69, 328.80856019913284), (339.43, 328.88983480342193), (338.34, 328.9621468864557), (338.34, 329.03390564187623), (338.64, 329.1074108852667), (338.64, 329.1803536710542), (338.64, 329.25273830312983), (340.73, 329.3405616039463), (340.38, 329.4250347077848), (341.63, 329.5184263517694), (342.89, 329.62074481116446), (343.015, 329.72323682831365), (344.58, 329.8369198666242), (345.27, 329.9550128468903), (344.52, 330.06646323304676), (344.44, 330.17644865261985), (345.47, 330.29347396719453), (346.73, 330.4192452537855), (346.57, 330.5428298360623), (346.47, 330.66470356286277), (346.77, 330.78794030095355), (347.97, 330.91941636531885), (347.36, 331.04521870042987), (349.46, 331.18612747468757), (350.985, 331.3376272299028), (350.3, 331.48272614042395), (352.79, 331.64576808990375), (352.73, 331.8071033361), (354.15, 331.9780698076025), (353.53, 332.14298385229813), (353.32, 332.30502907777566), (355.505, 332.48255382880495), (355.895, 332.6617044273752), (356.79, 332.8463326615506), (356.51, 333.02740558904617), (357.47, 333.21443881860756), (357.055, 333.39686532691286), (357.48, 333.5811479926617), (357.025, 333.7605389067591), (357.43, 333.94165616771005), (357.38, 334.1210049335906), (358.125, 334.3046820279352), (357.42, 334.4815590197948), (357.62, 334.65861294749095), (358.54, 334.8413518528518), (357.89, 335.0177186913104), (353.71, 335.1607508785756), (352.62, 335.2943479793577), (352.6, 335.42676976456875), (357.63, 335.59666751714803), (358.065, 335.7685938158246), (357.97, 335.93847761087585), (357.8, 336.10576063602537), (358.04, 336.27360008699543), (358.57, 336.4442107682189), (359.41, 336.6199435753518), (357.99, 336.7834659331593), (358.005, 336.9458518070169), (358.75, 337.1126958083452), (359.615, 337.28488205644874), (359.76, 337.45686027705335), (359.11, 337.6225487708539), (356.965, 337.77055601837424), (357.91, 337.92466180543283), (357.25, 338.0725381050648), (355.66, 338.2071162821066), (357.31, 338.35329037376084), (357.74, 338.5016362838145), (357.655, 338.6481966453118), (358.39, 338.7992597107424), (358.115, 338.947062567793), (357.65, 339.0901762950602), (357.9, 339.2341079095143), (359.97, 339.3927776808289), (359.615, 339.5475168826367), (362.8, 339.72544345375445), (361.99, 339.8958104714934), (362.48, 340.06862330115973), (361.25, 340.23070189330645), (361.25, 340.3915402700316), (362.85, 340.5633910230101), (362.85, 340.7339267845932), (363.67, 340.9094322065959), (363.67, 341.0835946719005), (366.22, 341.27593689994046), (366.23, 341.46688385646286), (366.23, 341.65636969861447), (366.23, 341.8444056067526), (367.87, 342.0435518548466), (368.0, 342.2421690001017), (366.42, 342.4271762763209), (366.42, 342.6107678882378), (366.42, 342.79295466842854), (366.42, 342.9737473665792), (366.47, 343.15353924704544), (366.8, 343.33448051080677), (366.8, 343.5140372231431), (366.8, 343.69221997855675), (370.55, 343.89773405991014), (370.78, 344.10343550600743), (369.98, 344.3014413864755), (374.29, 344.53091199311723), (374.775, 344.7623378949655), (376.0, 345.0013665647223), (375.41, 345.2340515580714), (375.51, 345.4657212540097), (375.77, 345.69760773169276), (373.62, 345.9112681605007), (370.75, 346.10133260930854), (371.42, 346.2950694954449), (367.18, 346.4548796995402), (362.83, 346.58018111324276), (361.99, 346.69809609988), (362.37, 346.81801654492494), (363.96, 346.9491859483355), (360.705, 347.05444459167234), (363.3, 347.1787545827868), (361.98, 347.2920128026537), (360.01, 347.38933005871286), (357.74, 347.46853274868494), (357.89, 347.54827717532027), (357.37, 347.62343239447875), (355.19, 347.68133130456016), (358.52, 347.76426813099397), (358.67, 347.8477181207085), (355.64, 347.9073441825346), (357.53, 347.98097615319364), (353.59, 348.0238960587944), (353.02, 348.0621259389633), (353.25, 348.10182323229805), (354.1, 348.14772091212217), (355.86, 348.20673479750735), (360.44, 348.30034299066534), (361.69, 348.40279982282766), (361.51, 348.5030953126774), (361.14, 348.5997921303552), (360.5, 348.69085178928054), (359.7, 348.77509311448324), (355.72, 348.8282351149584), (357.055, 348.89118581402994), (354.77, 348.93617013871767), (357.97, 349.00529644936444), (359.56, 349.08606039197), (358.89, 349.1610795350481), (356.68, 349.21861385213947), (357.27, 349.2802225638974), (357.19, 349.34074769449984), (358.79, 349.4130527921472), (358.42, 349.4819733983828), (357.63, 349.5443215969509), (357.3, 349.6036675712274), (357.94, 349.6674566744067), (359.01, 349.73894524150086), (369.66, 349.89137992765194), (369.46, 350.04111780525426), (368.98, 350.18603696733715), (370.15, 350.3387999849639), (370.3, 350.49154186014965), (368.325, 350.62800238533225), (368.39, 350.76391609896996), (368.64, 350.9007027938562), (368.43, 351.0348358982757), (370.27, 351.1820221912936)]\n",
      "input_data vs classes: [(311.3514908170164, 2), (311.3423353428517, 2), (311.3234171848216, 2), (311.3086993147861, 2), (311.29799655362945, 2), (311.2878730653465, 2), (311.30173934923044, 2), (311.3164942811696, 2), (311.3251677972356, 2), (311.3371417970363, 2), (311.34336173802615, 2), (311.35075839457227, 2), (311.3562619871139, 2), (311.3644781643689, 2), (311.37982429414416, 2), (311.39367564734533, 2), (311.4094105148572, 2), (311.42158160779894, 2), (311.43993415786747, 2), (311.46312003538566, 2), (311.48918927140033, 2), (311.5186554383256, 2), (311.55218121752125, 2), (311.5807827770222, 2), (311.6106958668513, 2), (311.63502370659626, 2), (311.66697036849183, 2), (311.70655407316457, 2), (311.7551702507503, 2), (311.80448569172637, 2), (311.8632947746637, 2), (311.9360777582137, 2), (312.01025505516975, 2), (312.0840943101658, 2), (312.15178263660727, 2), (312.23333866054344, 2), (312.31239589786304, 2), (312.38530053864076, 2), (312.4606698333029, 2), (312.5381023255439, 2), (312.6128762857164, 2), (312.6849737970518, 2), (312.7554100915788, 2), (312.83372454427666, 2), (312.91610742209133, 2), (312.99961985704863, 2), (313.0863574889382, 2), (313.1678019870005, 2), (313.25390311434614, 2), (313.33865672669305, 2), (313.4256695462448, 2), (313.50949140934176, 2), (313.59236579515556, 2), (313.6808041014612, 2), (313.7685656832847, 2), (313.8556557188802, 2), (313.9420793468781, 2), (314.02784166658836, 2), (314.1129477383014, 2), (314.1974025835865, 2), (314.28121118558823, 2), (314.3643784893205, 2), (314.4469094019582, 2), (314.52880879312687, 2), (314.61008149518995, 2), (314.69073230353393, 2), (314.77076597685135, 2), (314.8501872374215, 2), (314.92900077138904, 2), (315.0072112290406, 2), (315.084823225079, 2), (315.1618413388957, 2), (315.23827011484104, 2), (315.31411406249214, 2), (315.3893776569191, 2), (315.4640653389492, 2), (315.53818151542856, 2), (315.6117305594826, 2), (315.6847168107738, 2), (315.7571445757577, 2), (315.87072119283994, 2), (315.98603038772643, 2), (316.1006102825138, 2), (316.22081756672844, 2), (316.35051166857465, 2), (316.47875424281705, 2), (316.60142434965786, 2), (316.7210132495996, 2), (316.83769755861834, 2), (316.9577358323543, 2), (317.07490433627913, 2), (317.20028208084807, 2), (317.3270725435639, 2), (317.454844057776, 2), (317.58749160518084, 2), (317.7192389207866, 2), (317.8436652647597, 2), (317.97173066910767, 2), (318.09648228360896, 2), (318.2183280621054, 2), (318.33373208846626, 2), (318.4455748718332, 2), (318.5678867100996, 2), (318.6904104164771, 2), (318.81811812979834, 2), (318.9424382709175, 2), (319.0889542359663, 2), (319.21766784389814, 2), (319.3540432337372, 2), (319.48654387022805, 2), (319.6298146053074, 2), (319.8051219352977, 2), (319.96584997074814, 2), (320.1319287922761, 2), (320.29470902516687, 2), (320.4604904995997, 2), (320.62419997083936, 2), (320.7759057736584, 2), (320.91527890277115, 2), (321.04524494428887, 2), (321.17811898229024, 2), (321.30331908981526, 2), (321.4296271972144, 2), (321.55894781076927, 2), (321.67641311825037, 2), (321.795657766901, 2), (321.9304798903302, 2), (322.06545641363033, 2), (322.1964158488527, 2), (322.33620593151977, 2), (322.47090908134936, 2), (322.61242472793583, 2), (322.7586729787667, 2), (322.9100384768635, 2), (323.0577971151511, 2), (323.1905751047128, 2), (323.3165216119915, 2), (323.4308681898056, 2), (323.5603323461317, 2), (323.69722298305953, 2), (323.82725066797957, 2), (323.9588467884517, 2), (324.0868342844064, 2), (324.220843951652, 2), (324.347094479271, 2), (324.47306762008157, 2), (324.5936386978259, 2), (324.71412888633336, 2), (324.8343092464079, 2), (324.9564012110068, 2), (325.07449815999377, 2), (325.18970193437474, 2), (325.3076205876592, 2), (325.4266264386727, 2), (325.5423495632921, 2), (325.65883234845774, 2), (325.7724725701922, 2), (325.88336849900116, 2), (325.98082842012553, 2), (326.07731302577037, 2), (326.19238048189374, 2), (326.3056874759887, 2), (326.42256557626985, 2), (326.5414570691495, 2), (326.65216947004717, 2), (326.7677736603461, 2), (326.8841384212695, 2), (326.99846497541984, 2), (327.1079759614725, 2), (327.2209340617612, 2), (327.33306607330445, 2), (327.4419296969578, 2), (327.54766472130234, 2), (327.64754038832234, 2), (327.7425962854667, 2), (327.83531791364265, 2), (327.9270622237729, 2), (328.0175306166944, 2), (328.1051642082518, 2), (328.19625927975255, 2), (328.28329044442097, 2), (328.3721807916782, 2), (328.45782755606143, 2), (328.54396674744675, 2), (328.6018615686921, 2), (328.66818963100144, 2), (328.7323649882757, 2), (328.80856019913284, 2), (328.88983480342193, 2), (328.9621468864557, 2), (329.03390564187623, 2), (329.1074108852667, 2), (329.1803536710542, 2), (329.25273830312983, 2), (329.3405616039463, 2), (329.4250347077848, 2), (329.5184263517694, 2), (329.62074481116446, 2), (329.72323682831365, 2), (329.8369198666242, 2), (329.9550128468903, 2), (330.06646323304676, 2), (330.17644865261985, 2), (330.29347396719453, 2), (330.4192452537855, 2), (330.5428298360623, 2), (330.66470356286277, 2), (330.78794030095355, 2), (330.91941636531885, 2), (331.04521870042987, 2), (331.18612747468757, 2), (331.3376272299028, 2), (331.48272614042395, 2), (331.64576808990375, 2), (331.8071033361, 2), (331.9780698076025, 2), (332.14298385229813, 2), (332.30502907777566, 2), (332.48255382880495, 2), (332.6617044273752, 2), (332.8463326615506, 2), (333.02740558904617, 2), (333.21443881860756, 2), (333.39686532691286, 2), (333.5811479926617, 2), (333.7605389067591, 2), (333.94165616771005, 2), (334.1210049335906, 2), (334.3046820279352, 2), (334.4815590197948, 2), (334.65861294749095, 2), (334.8413518528518, 2), (335.0177186913104, 2), (335.1607508785756, 2), (335.2943479793577, 2), (335.42676976456875, 2), (335.59666751714803, 2), (335.7685938158246, 2), (335.93847761087585, 2), (336.10576063602537, 2), (336.27360008699543, 2), (336.4442107682189, 2), (336.6199435753518, 2), (336.7834659331593, 2), (336.9458518070169, 2), (337.1126958083452, 2), (337.28488205644874, 2), (337.45686027705335, 2), (337.6225487708539, 2), (337.77055601837424, 2), (337.92466180543283, 2), (338.0725381050648, 2), (338.2071162821066, 2), (338.35329037376084, 2), (338.5016362838145, 2), (338.6481966453118, 2), (338.7992597107424, 2), (338.947062567793, 2), (339.0901762950602, 2), (339.2341079095143, 2), (339.3927776808289, 2), (339.5475168826367, 2), (339.72544345375445, 2), (339.8958104714934, 2), (340.06862330115973, 2), (340.23070189330645, 2), (340.3915402700316, 2), (340.5633910230101, 2), (340.7339267845932, 2), (340.9094322065959, 2), (341.0835946719005, 2), (341.27593689994046, 2), (341.46688385646286, 2), (341.65636969861447, 2), (341.8444056067526, 2), (342.0435518548466, 2), (342.2421690001017, 2), (342.4271762763209, 2), (342.6107678882378, 2), (342.79295466842854, 2), (342.9737473665792, 2), (343.15353924704544, 2), (343.33448051080677, 2), (343.5140372231431, 2), (343.69221997855675, 2), (343.89773405991014, 2), (344.10343550600743, 2), (344.3014413864755, 2), (344.53091199311723, 2), (344.7623378949655, 2), (345.0013665647223, 2), (345.2340515580714, 2), (345.4657212540097, 2), (345.69760773169276, 2), (345.9112681605007, 2), (346.10133260930854, 2), (346.2950694954449, 2), (346.4548796995402, 2), (346.58018111324276, 2), (346.69809609988, 2), (346.81801654492494, 2), (346.9491859483355, 2), (347.05444459167234, 2), (347.1787545827868, 2), (347.2920128026537, 2), (347.38933005871286, 2), (347.46853274868494, 2), (347.54827717532027, 2), (347.62343239447875, 2), (347.68133130456016, 2), (347.76426813099397, 2), (347.8477181207085, 2), (347.9073441825346, 2), (347.98097615319364, 2), (348.0238960587944, 2), (348.0621259389633, 2), (348.10182323229805, 2), (348.14772091212217, 2), (348.20673479750735, 2), (348.30034299066534, 2), (348.40279982282766, 2), (348.5030953126774, 2), (348.5997921303552, 2), (348.69085178928054, 2), (348.77509311448324, 2), (348.8282351149584, 2), (348.89118581402994, 2), (348.93617013871767, 2), (349.00529644936444, 2), (349.08606039197, 2), (349.1610795350481, 2), (349.21861385213947, 2), (349.2802225638974, 2), (349.34074769449984, 1), (349.4130527921472, 1), (349.4819733983828, 1), (349.5443215969509, 1), (349.6036675712274, 1), (349.6674566744067, 1), (349.73894524150086, 1), (349.89137992765194, 1), (350.04111780525426, 1), (350.18603696733715, 1), (350.3387999849639, 1), (350.49154186014965, 1), (350.62800238533225, 1), (350.76391609896996, 1), (350.9007027938562, 1), (351.0348358982757, 1), (351.1820221912936, 1)]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# If quotes every 15min there 26 per day if quotes every 5min there are 78 per day\n",
    "TICKS_IN_DAY = 26 if DATA_INTERVAL_MINUTES == 15 else 78\n",
    "# How many data ticks are inspecting to determine the if up or down by percentage \n",
    "TICKS_PREDICT= TICKS_IN_DAY * DAYS_PREDICT\n",
    "REACH_PCT= 0.95\n",
    "\n",
    "import classifiers.up_down_classifier as udc\n",
    "import classifiers.ewa_classifier as ec\n",
    "\n",
    "alpha= ec.calculate_ewa_alpha(TICKS_PREDICT, REACH_PCT)\n",
    "print(f\"alpha: {alpha:.4f} for window: {TICKS_PREDICT} and reach: {REACH_PCT}\")\n",
    "\n",
    "classes_calc = udc.UpsDownsClassifier(TICKS_PREDICT, DOWN_PCTS_PREDICT, UP_PCTS_PREDICT)\n",
    "\n",
    "close_prices = df['close'].astype(float).tolist()\n",
    "input_data= ec.calculate_ewas(close_prices, alpha)\n",
    "\n",
    "classes= classes_calc.classify(input_data)\n",
    "print(f\"Check correct 'nan' point (window={TICKS_PREDICT}): {classes[-TICKS_PREDICT-1:-TICKS_PREDICT+1]}\")\n",
    "print(f\"prices vs input_data: {[(p, c) for p, c in zip(close_prices[2650:3000], input_data[2650:3000])]}\")\n",
    "print(f\"input_data vs classes: {[(p, c) for p, c in zip(input_data[2650:3000], classes[2650:3000])]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "id": "15a25bdb-a1ac-49b9-b508-55aa08e54c34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Create a histogram\n",
    "hist_values, bin_edges, _ = plt.hist(classes, bins=21, edgecolor='black')\n",
    "\n",
    "# Add labels and a title\n",
    "plt.xlabel('Value')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Histogram of Data')\n",
    "\n",
    "# Display frequency on top of each bar\n",
    "for value, edge in zip(hist_values, bin_edges[:-1]):\n",
    "    plt.text(edge, value, str(int(value)), color='black')\n",
    "    \n",
    "# Show the histogram\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "id": "0d689836",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total: 47294\n",
      " 33.86%  16015 times -5.0% change (0)\n",
      " 31.57%  14933 times   0% change (1)\n",
      " 33.74%  15956 times 7.0% change (2)\n",
      "  0.82%    390 times   0% change (nan)\n"
     ]
    }
   ],
   "source": [
    "# Show percentages of each class value\n",
    "import utils.list_utils as lu\n",
    "\n",
    "lu.display_frequency_classes(classes, DOWN_PCTS_PREDICT, UP_PCTS_PREDICT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "id": "1c8ce196",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 2000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Display classes value changes over time (last 500 ticks)\n",
    "graph_ticks = 500\n",
    "x = range(len(classes[-graph_ticks:]))\n",
    "\n",
    "plt.figure(figsize=(20,5))\n",
    "plt.plot(x, classes[-graph_ticks:], linestyle='-')\n",
    "\n",
    "\n",
    "plt.xlabel('Index')\n",
    "plt.ylabel('Class')\n",
    "plt.title('Plot of Classes')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "id": "1347910b-5c73-4c91-847e-906b66ad4e86",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Calculate the signals as input for the neural network as proportions\n",
    "import preprocessing.proportions_calc as proportions\n",
    "\n",
    "signals_calculator = proportions.ProportionsCalc(signal_avg)\n",
    "\n",
    "proportions_avg = signals_calculator.calculate(close_prices)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "id": "78ac18bb-6cb7-4307-ab28-e8b5d5f2a74e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prices length: 47294\n",
      "Proportions length: 47294\n",
      "Last 10 close: [250.6, 250.715, 249.965, 249.415, 250.09, 250.605, 250.4, 250.4, 249.19, 248.5]\n",
      "Last 10 proportions(avg=2): [0.001486432561795425, 0.00022934407588670722, -0.0015002100294603995, -0.0011025800373436819, 0.001349514174840805, 0.001027513417473412, -0.000409345047979476, -5.618508853055105e-14, -0.002427866286825549, -0.0013883299799358857]\n",
      "Proportions avgs: Count: 16 Max: 2584\n",
      "Classes last non-nan: [1, nan] len: 47294\n",
      "Proportions first non-nan(avg=2584): [nan, 0.11402957095848261] len: 47294\n",
      "Proportions (avg=2) Min: -1.9502283711002686 Max: 0.07537671689559655\n",
      "Proportions (avg=2584) Min: -2.487705376731546 Max: 0.6134148294687675\n"
     ]
    }
   ],
   "source": [
    "print(f\"Prices length: {len(close_prices)}\")\n",
    "print(f\"Proportions length: {len(proportions_avg[-1])}\")\n",
    "\n",
    "print(f\"Last 10 close: {close_prices[-10:]}\")\n",
    "print(f\"Last 10 proportions(avg={signal_avg[0]}): {proportions_avg[0][-10:]}\")\n",
    "\n",
    "print(f\"Proportions avgs: Count: {len(signal_avg)} Max: {signal_avg[-1]}\")\n",
    "# At the end of the data, when less ticks than necessary no possible to predict so \"nan\" \n",
    "print(f\"Classes last non-nan: {classes[-TICKS_PREDICT-1:-TICKS_PREDICT+1]} len: {len(classes)}\")\n",
    "print(f\"Proportions first non-nan(avg={signal_avg[-1]}): {proportions_avg[-1][signal_avg[-1]-2:signal_avg[-1]]} len: {len(proportions_avg[-1])}\")\n",
    "print(f\"Proportions (avg={signal_avg[0]}) Min: {min(proportions_avg[0][signal_avg[0]-1:-TICKS_PREDICT-1])} Max: {max(proportions_avg[0][signal_avg[0]-1:-TICKS_PREDICT])}\")\n",
    "print(f\"Proportions (avg={signal_avg[-1]}) Min: {min(proportions_avg[-1][signal_avg[-1]-1:-TICKS_PREDICT-1])} Max: {max(proportions_avg[-1][signal_avg[-1]-1:-TICKS_PREDICT])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "id": "b7bb2e59-3b6b-4691-8d9e-a5b0754c6f3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.0003727231477269334, -0.0001458907440417405]\n",
      "[-0.0009615176854427643, -0.0004430755930184548]\n",
      "[0.0001750178258897727, -0.0001685848597828527]\n",
      "[-0.00013369417255900415, -6.0787810022290846e-05]\n",
      "[-0.0028833064906182465, -0.002512562814070278]\n",
      "[-0.006446644256978007, -0.005943696979522491]\n",
      "[-0.010900960500879488, -0.010669571767757994]\n",
      "[-0.01059741775046441, -0.010780294434050569]\n",
      "[-0.007264368686739381, -0.007245542682604316]\n",
      "[-0.015404652197086699, -0.015328997136219462]\n",
      "[-0.027568646019697888, -0.027699831011624574]\n",
      "[-0.01854184824257448, -0.018706994371188678]\n",
      "[-0.012875100818555793, -0.013213236994065606]\n",
      "[0.005063869455054647, 0.004668290302711154]\n",
      "[0.06954253289545267, 0.06916454533154584]\n",
      "[0.11402957095848261, 0.11365373883298692]\n",
      "First target: 2 and last target: 1\n",
      "Classes: 47294 after cut to targets: 44321\n",
      "Inputs len: 44321\n",
      "Distinct targets: [0, 1, 2]\n"
     ]
    }
   ],
   "source": [
    "# Removing the \"nan\" from the proportions\n",
    "#   At the beging first signal_avg[-1] are \"nan\" (need previous values for first avg.)\n",
    "#   At the end decided not predict if period to predict is shorter\n",
    "targets = classes[signal_avg[-1]-1:-TICKS_PREDICT]\n",
    "inputs = []\n",
    "for proportion in proportions_avg:\n",
    "    proportion_cut= proportion[signal_avg[-1]-1:-TICKS_PREDICT]\n",
    "    print(proportion_cut[:2])\n",
    "    inputs.append(proportion_cut)\n",
    "\n",
    "print(f\"First target: {targets[0]} and last target: {targets[-1]}\")\n",
    "print(f\"Classes: {len(classes)} after cut to targets: {len(targets)}\")\n",
    "print(f\"Inputs len: {len(inputs[len(signal_avg)-1])}\")\n",
    "print(f\"Distinct targets: {list(set(targets))}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "id": "9e9db662-5306-4859-856f-e962f1996b55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data: 'nan' removed from begining and end\n",
      "Total: 44321\n",
      " 35.61%  15784 times -5.0% change (0)\n",
      " 31.31%  13875 times   0% change (1)\n",
      " 33.08%  14662 times 7.0% change (2)\n",
      "VALIDATE removing should be POSITIVE?\n",
      "Removing 0: 8453\n",
      "Removing 1: 6544\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "print(\"Train data: 'nan' removed from begining and end\")\n",
    "lu.display_frequency_classes(targets, DOWN_PCTS_PREDICT, UP_PCTS_PREDICT)\n",
    "\n",
    "targets_frequency = Counter(targets)\n",
    "print(\"VALIDATE removing should be POSITIVE?\")\n",
    "count_remove_a= targets_frequency[INDEX_REMOVE_A] - targets_frequency[INDEX_KEEP] + targets_frequency[INDEX_KEEP] //2\n",
    "count_remove_b= targets_frequency[INDEX_REMOVE_B] - targets_frequency[INDEX_KEEP] + targets_frequency[INDEX_KEEP] //2\n",
    "print(f\"Removing {INDEX_REMOVE_A}: {count_remove_a}\")\n",
    "print(f\"Removing {INDEX_REMOVE_B}: {count_remove_b}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "id": "6bd505db-6ec0-43f7-a761-abcc231d549b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total: 44321\n",
      " 35.61%  15784 times -5.0% change (0)\n",
      " 31.31%  13875 times   0% change (1)\n",
      " 33.08%  14662 times 7.0% change (2)\n",
      "Targets len: 44321 Targets clean: 44321 Difference: 0\n",
      "targets_clean positions(Keep=2)(First:0,Last:-448)\n"
     ]
    }
   ],
   "source": [
    "###################\n",
    "##### SET PARAMETERS\n",
    "###################\n",
    "# DECISION SET: REMOVING?\n",
    "indexes_remove_a= []\n",
    "# 2024-03-01 Do not remove anything\n",
    "# if count_remove_a > 0:\n",
    "#     indexes_remove_a = get_indexes_value(targets, index_remove_a, count_remove_a)\n",
    "\n",
    "# DECISION SET: REMOVING?\n",
    "indexes_remove_b= []\n",
    "# 2024-03-01 Do not remove anything\n",
    "# if count_remove_b > 0:\n",
    "#     indexes_remove_b = get_indexes_value(targets, index_remove_b, count_remove_b)\n",
    "\n",
    "indexes_remove= indexes_remove_a + indexes_remove_b\n",
    "targets_clean= lu.remove_indexes(targets, indexes_remove)\n",
    "\n",
    "lu.display_frequency_classes(targets_clean, DOWN_PCTS_PREDICT, UP_PCTS_PREDICT)\n",
    "print(f\"Targets len: {len(targets)} Targets clean: {len(targets_clean)} Difference: {len(targets)-len(targets_clean)}\")\n",
    "\n",
    "inputs_clean = [lu.remove_indexes(input, indexes_remove) for input in inputs]    \n",
    "print(f\"targets_clean positions(Keep={INDEX_KEEP})(First:{targets_clean.index(INDEX_KEEP)},Last:-{targets_clean[::-1].index(INDEX_KEEP)})\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "id": "39663265",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "targets_binary First 0 and Last(counting from end) 448 position with True\n",
      "targets_binary len: 44321 Input clean[0]: 44321 Input clean[-1]: 44321\n"
     ]
    }
   ],
   "source": [
    "# Sets 'index_keep' as target = 1 and rest of indexes to target=0\n",
    "targets_binary= lu.convert_binary(targets_clean, INDEX_KEEP)\n",
    "print(f\"targets_binary First {targets_binary.index(True)} and Last(counting from end) {targets_binary[::-1].index(True)} position with True\")\n",
    "print(f\"targets_binary len: {len(targets_binary)} Input clean[0]: {len(inputs_clean[0])} Input clean[-1]: {len(inputs_clean[-1])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "id": "a66b9612-5714-45ea-9237-af591665f186",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inputs_tensor: torch.Size([16, 44321])\n",
      "inputs_tensor: torch.Size([44321, 16])\n",
      "inputs_clean len0 x len1: 16 x 44321 -> inputs_tensor.shape: torch.Size([44321, 16])\n",
      "targets_binary.shape: 44321 -> targets_tensor.shape: torch.Size([44321])\n",
      "inputs_tensor: tensor([[-0.0004, -0.0010,  0.0002,  ...,  0.0051,  0.0695,  0.1140],\n",
      "        [-0.0001, -0.0004, -0.0002,  ...,  0.0047,  0.0692,  0.1137],\n",
      "        [-0.0003, -0.0004, -0.0012,  ...,  0.0040,  0.0686,  0.1131],\n",
      "        ...,\n",
      "        [ 0.0002,  0.0002, -0.0006,  ...,  0.0696,  0.0232,  0.0055],\n",
      "        [-0.0007, -0.0009, -0.0016,  ...,  0.0683,  0.0219,  0.0041],\n",
      "        [ 0.0007,  0.0004,  0.0003,  ...,  0.0696,  0.0233,  0.0055]])\n",
      "targets_tensor: tensor([1., 1., 1.,  ..., 0., 0., 0.])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "inputs_tensor = torch.Tensor(inputs_clean)\n",
    "print(f\"inputs_tensor: {inputs_tensor.size()}\")\n",
    "inputs_tensor = inputs_tensor.T\n",
    "print(f\"inputs_tensor: {inputs_tensor.size()}\")\n",
    "targets_tensor = torch.Tensor(targets_binary)\n",
    "print(f\"inputs_clean len0 x len1: {len(inputs_clean)} x {len(inputs_clean[0])} -> inputs_tensor.shape: {inputs_tensor.shape}\")\n",
    "print(f\"targets_binary.shape: {len(targets_binary)} -> targets_tensor.shape: {targets_tensor.shape}\")\n",
    "print(f\"inputs_tensor: {inputs_tensor}\")\n",
    "print(f\"targets_tensor: {targets_tensor}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "id": "9a759cdf-b8e5-4f12-8b93-49d296c9b403",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inputs_tensor.size(0): 44321\n",
      "inputs_tensor.shape: torch.Size([44321, 16]) -> inputs_tensor_shuffle.shape: torch.Size([44321, 16])\n",
      "targets_tensor.shape: torch.Size([44321]) -> targets_tensor_shuffle.shape: torch.Size([44321])\n"
     ]
    }
   ],
   "source": [
    "#Shuffle tensors\n",
    "torch.manual_seed(42) \n",
    "permutation = torch.randperm(inputs_tensor.size(0))\n",
    "inputs_tensor_shuffle = inputs_tensor[permutation]\n",
    "\n",
    "targets_tensor_shuffle = targets_tensor[permutation]\n",
    "\n",
    "print(f\"inputs_tensor.size(0): {inputs_tensor.size(0)}\")\n",
    "print(f\"inputs_tensor.shape: {inputs_tensor.shape} -> inputs_tensor_shuffle.shape: {inputs_tensor_shuffle.shape}\")\n",
    "print(f\"targets_tensor.shape: {targets_tensor.shape} -> targets_tensor_shuffle.shape: {targets_tensor_shuffle.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "id": "509cc3f9-10c5-43d0-83a5-4224daee46f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_test_split= int(TRAIN_SPLIT * len(targets_tensor))\n",
    "inputs_tensor_train, targets_tensor_train= inputs_tensor_shuffle[:train_test_split], targets_tensor_shuffle[:train_test_split]\n",
    "inputs_tensor_test, targets_tensor_test= inputs_tensor_shuffle[train_test_split:], targets_tensor_shuffle[train_test_split:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "id": "89daca86-671c-4257-ba5b-93807f06edbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training dataset frequencies:\n",
      "Total: 39888\n",
      " 66.88%  26676 times (0.0)\n",
      " 33.12%  13212 times (1.0)\n",
      "Validation dataset frequencies:\n",
      "Total: 4433\n",
      " 67.29%   2983 times (0.0)\n",
      " 32.71%   1450 times (1.0)\n"
     ]
    }
   ],
   "source": [
    "print(\"Training dataset frequencies:\")\n",
    "lu.display_frequency_values(targets_tensor_train.tolist())\n",
    "print(\"Validation dataset frequencies:\")\n",
    "lu.display_frequency_values(targets_tensor_test.tolist())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "id": "b45cbcce-5556-49c1-8701-3b38771b10ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Tuple\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "class StockDataset(Dataset):\n",
    "    def __init__(\n",
    "        self,\n",
    "        inputs,\n",
    "        targets):\n",
    "        \n",
    "        self.inputs= inputs\n",
    "        self.targets= targets\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return len(self.targets)\n",
    "\n",
    "    def __getitem__(self, index: int) -> Tuple[torch.Tensor, int]:\n",
    "        return self.inputs[index], self.targets[index]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "id": "0e1e55d5-e9e3-4a93-af46-f8ec7eb92f60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_dataset: (tensor([ 0.0002,  0.0003,  0.0002, -0.0003, -0.0012, -0.0018, -0.0039, -0.0027,\n",
      "         0.0003, -0.0060, -0.0150, -0.0450, -0.0445, -0.0518, -0.0767, -0.1343]), tensor(1.))\n",
      "train_input0: tensor([[ 2.2565e-04,  3.1892e-04,  2.0579e-04, -3.0011e-04, -1.2484e-03,\n",
      "         -1.8275e-03, -3.8636e-03, -2.6572e-03,  2.6855e-04, -5.9798e-03,\n",
      "         -1.5003e-02, -4.4968e-02, -4.4510e-02, -5.1774e-02, -7.6663e-02,\n",
      "         -1.3426e-01],\n",
      "        [-1.0373e-03, -1.5457e-03,  2.8474e-04,  3.6381e-03,  6.2256e-03,\n",
      "          9.6730e-03,  1.5613e-02,  1.4329e-02,  1.6881e-03, -5.5279e-03,\n",
      "         -4.3219e-03,  7.8376e-03,  5.6513e-02,  1.0444e-01,  1.8568e-01,\n",
      "          2.4162e-01],\n",
      "        [ 6.9929e-16,  5.2447e-16,  1.7482e-16, -4.5454e-15, -5.2447e-16,\n",
      "          1.0435e-03,  4.0705e-03,  1.4180e-02,  2.7208e-02,  3.7461e-02,\n",
      "          3.8900e-02,  2.8943e-02,  3.4360e-02,  4.5564e-02,  1.0107e-01,\n",
      "          1.4545e-01],\n",
      "        [ 1.0379e-14,  9.8599e-15,  7.3035e-05, -5.4168e-03, -1.0108e-02,\n",
      "         -1.2038e-02, -1.5425e-02, -1.2891e-02, -1.4154e-02, -3.4468e-02,\n",
      "         -4.5034e-02, -3.3139e-02, -2.3185e-02, -3.3872e-02, -1.9174e-02,\n",
      "          1.0485e-03],\n",
      "        [-6.8367e-04, -6.7347e-04,  8.6122e-04,  2.2934e-03,  3.3846e-03,\n",
      "         -2.7998e-03, -7.9256e-03, -1.0663e-02, -1.8568e-02, -2.8721e-02,\n",
      "         -4.6812e-02, -6.0817e-02, -9.1547e-02, -8.6586e-02, -2.7259e-04,\n",
      "          1.0589e-01],\n",
      "        [ 1.4962e-03,  1.6519e-04,  1.1284e-03,  2.3730e-03, -1.3489e-04,\n",
      "         -2.8064e-03, -2.5435e-02, -4.6672e-02, -6.1632e-02, -9.2679e-02,\n",
      "         -1.2235e-01, -1.5584e-01, -2.1855e-01, -2.1014e-01, -2.3211e-01,\n",
      "         -1.9213e-01],\n",
      "        [ 3.5513e-03,  5.1429e-03,  2.7440e-02,  3.9983e-02,  4.8023e-02,\n",
      "          5.2923e-02,  5.6302e-02,  5.9041e-02,  6.0067e-02,  4.5163e-02,\n",
      "          6.7329e-02,  1.1454e-01,  1.6158e-01,  2.3947e-01,  2.9506e-01,\n",
      "          3.9359e-01],\n",
      "        [-2.6188e-04,  1.1036e-03,  1.2545e-04, -1.4250e-03, -1.3873e-03,\n",
      "          6.2344e-03,  2.1087e-02,  4.0155e-02,  2.1970e-02,  6.1408e-03,\n",
      "          2.0753e-02,  3.2959e-02,  1.2411e-01,  2.2103e-01,  1.4322e-01,\n",
      "          2.0945e-01],\n",
      "        [ 2.4955e-03,  5.0865e-03,  7.9201e-03,  3.2948e-02,  4.8069e-02,\n",
      "          6.3761e-02,  8.2820e-02,  9.0204e-02,  8.9736e-02,  7.2864e-02,\n",
      "          6.3451e-02, -5.6407e-03, -1.4726e-01, -2.8269e-01, -4.5387e-01,\n",
      "         -9.1833e-01],\n",
      "        [-2.7046e-03, -5.0225e-03, -3.8374e-03, -5.5216e-03, -9.3156e-03,\n",
      "         -1.2550e-02, -4.1023e-03, -2.1388e-03, -1.9016e-03, -1.5913e-02,\n",
      "         -5.9068e-02, -1.0620e-01, -1.6259e-01, -1.6671e-01, -1.6485e-01,\n",
      "         -2.6080e-01],\n",
      "        [-1.9966e-04, -1.5640e-03,  5.4574e-04,  2.4167e-03,  4.8226e-03,\n",
      "          6.9192e-03,  7.6248e-03,  7.5835e-03,  1.6737e-02,  1.9391e-02,\n",
      "          2.9898e-02,  4.3699e-02,  1.2348e-02, -4.2509e-02, -4.2128e-02,\n",
      "         -4.0666e-02],\n",
      "        [-9.5690e-04, -2.8513e-03, -5.3435e-03, -7.6800e-03, -8.6462e-03,\n",
      "         -8.9328e-03, -5.2420e-03,  4.1183e-04,  2.6821e-03,  2.4013e-03,\n",
      "          8.1255e-03,  5.9989e-03,  1.3949e-02,  9.1514e-02,  1.9237e-01,\n",
      "          3.1190e-01],\n",
      "        [ 1.2434e-14,  1.0057e-14, -3.2915e-15, -1.0972e-15, -3.6178e-03,\n",
      "         -1.3352e-02, -3.9164e-02, -6.7417e-02, -9.0596e-02, -9.6754e-02,\n",
      "         -9.5663e-02, -1.1542e-01, -7.3216e-02, -1.2557e-02,  1.2589e-02,\n",
      "          6.9942e-05],\n",
      "        [ 3.2607e-03,  3.2783e-03,  4.3898e-03,  6.7878e-03,  8.3250e-03,\n",
      "          9.2619e-03,  1.0082e-02,  1.2233e-02,  2.3367e-03,  6.2895e-03,\n",
      "          6.8047e-03,  3.7004e-02,  6.7262e-02,  2.2486e-02, -1.7650e-02,\n",
      "         -3.9595e-02],\n",
      "        [-1.0609e-03, -1.0104e-03, -5.7411e-03, -6.0473e-03, -5.7208e-03,\n",
      "         -4.8442e-03, -2.4852e-03, -9.4064e-03, -2.7283e-02, -4.6298e-02,\n",
      "         -4.2541e-02, -2.5024e-02, -2.2095e-02, -3.0111e-02, -1.3908e-02,\n",
      "          4.2306e-03],\n",
      "        [-4.6688e-04, -5.4158e-04, -1.7144e-03, -5.1870e-03, -6.1499e-03,\n",
      "         -3.5092e-03, -3.2511e-03, -1.2700e-02, -1.5862e-02, -1.8126e-02,\n",
      "         -3.3709e-02, -2.7015e-02, -2.9421e-02, -5.5061e-02, -8.9980e-02,\n",
      "         -1.5748e-01],\n",
      "        [-4.8724e-04, -1.4710e-03, -5.8747e-04, -4.3678e-04, -3.2276e-03,\n",
      "          1.1884e-02,  2.1707e-02,  3.3465e-02,  5.4052e-02,  7.0044e-02,\n",
      "          7.9378e-02,  8.3526e-02,  7.8713e-02,  9.2645e-02,  1.1848e-01,\n",
      "          9.0144e-02],\n",
      "        [-5.3238e-04, -5.3084e-03, -1.0032e-02, -1.4230e-02, -2.1213e-02,\n",
      "         -2.7781e-02, -3.3524e-02, -4.4704e-02, -6.2400e-02, -8.3358e-02,\n",
      "         -1.0651e-01, -1.4340e-01, -1.8825e-01, -2.1367e-01, -1.6175e-01,\n",
      "         -2.6760e-02],\n",
      "        [ 2.7738e-03,  1.0411e-03, -4.0464e-03, -8.5048e-03, -1.2042e-02,\n",
      "         -1.4758e-02, -3.4526e-02, -4.8353e-02, -5.9652e-02, -6.7558e-02,\n",
      "         -9.6844e-02, -1.1263e-01, -1.5399e-01, -2.0341e-01, -2.4918e-01,\n",
      "         -3.3269e-01],\n",
      "        [-1.4696e-03, -5.7150e-04,  4.5230e-03,  1.4571e-02,  2.2320e-02,\n",
      "          2.5936e-02,  2.9649e-02,  2.9487e-02,  2.5644e-02,  1.7846e-02,\n",
      "          2.6656e-02,  2.8196e-02,  5.8147e-02,  6.9110e-02,  2.1113e-02,\n",
      "          5.5935e-03],\n",
      "        [ 5.8840e-04,  2.4494e-03,  1.6557e-03, -1.0528e-03, -1.4384e-02,\n",
      "         -2.1384e-02, -2.6084e-02, -2.7806e-02, -2.6261e-02, -1.9558e-02,\n",
      "         -2.3988e-02, -1.7116e-02,  5.5029e-03,  1.9397e-02,  4.8036e-02,\n",
      "          9.0538e-02],\n",
      "        [-4.8377e-03, -6.4935e-05,  5.5383e-02,  8.9255e-02,  1.0658e-01,\n",
      "          1.1132e-01,  9.6970e-02,  5.7929e-02,  3.7160e-02,  3.4958e-02,\n",
      "          3.9448e-02,  4.8857e-02,  5.1523e-02,  1.3781e-03, -8.9316e-03,\n",
      "         -1.4417e-02],\n",
      "        [-4.3825e-03, -6.4428e-03, -2.7826e-03,  7.1336e-03,  1.1895e-02,\n",
      "          1.4798e-02,  6.2544e-03, -7.0289e-03, -2.3813e-02, -4.6205e-02,\n",
      "         -1.0467e-01, -9.9849e-02, -1.4819e-02,  7.6381e-02,  1.5152e-01,\n",
      "          2.1958e-01],\n",
      "        [ 4.5142e-05, -3.4308e-04, -6.7532e-04, -1.3588e-03, -3.2058e-03,\n",
      "         -2.5357e-03, -1.8811e-03,  9.0645e-04,  1.2344e-02,  2.6027e-02,\n",
      "          2.4856e-02,  5.9880e-03, -1.5984e-02, -5.0565e-02, -8.6849e-02,\n",
      "         -1.4326e-01],\n",
      "        [ 2.5547e-03,  3.3094e-03,  5.4335e-03,  7.9628e-03,  1.0131e-02,\n",
      "          1.1519e-02,  1.4923e-02,  2.4599e-02,  3.2005e-02,  3.0429e-02,\n",
      "          3.8043e-02,  5.4101e-02,  6.8626e-02,  1.1668e-01,  6.4702e-02,\n",
      "         -2.2575e-02],\n",
      "        [ 2.9975e-03,  3.2373e-03, -5.3865e-03, -1.3523e-02, -1.8850e-02,\n",
      "         -2.0269e-02, -2.8189e-02, -4.6993e-02, -5.5463e-02, -5.8729e-02,\n",
      "         -6.1567e-02, -4.8477e-02, -1.9339e-02, -1.4749e-02,  2.2072e-02,\n",
      "          1.1371e-02],\n",
      "        [ 9.5581e-04,  1.8981e-03,  2.5461e-03,  6.0094e-03,  9.2906e-03,\n",
      "          1.9631e-02,  2.5993e-02,  3.2674e-02,  3.6341e-02,  3.7120e-02,\n",
      "          3.9116e-02,  5.8470e-02,  9.1061e-02,  6.2913e-02,  2.1867e-02,\n",
      "          1.7224e-03],\n",
      "        [ 5.3232e-04,  1.2631e-03,  4.3959e-04,  4.4088e-03,  9.6742e-03,\n",
      "          1.2756e-02,  1.5912e-02,  2.1859e-02,  3.0565e-02,  5.7438e-02,\n",
      "          4.4036e-02,  4.4508e-02,  5.9871e-03, -1.2395e+00, -1.6943e+00,\n",
      "         -1.4992e+00],\n",
      "        [ 4.1711e-15,  5.6727e-15,  3.3369e-16,  6.4206e-04,  3.4341e-03,\n",
      "          5.4363e-03,  8.0198e-04, -4.7981e-03, -9.0170e-03, -2.5753e-02,\n",
      "         -5.7539e-02, -6.3145e-02, -5.0001e-02, -4.6974e-02, -1.6929e-02,\n",
      "         -1.8425e-02],\n",
      "        [ 5.2552e-03,  8.0098e-03,  1.1648e-02,  9.4643e-03,  5.4251e-03,\n",
      "          3.6293e-03, -2.6866e-02, -7.1341e-02, -1.0489e-01, -1.4255e-01,\n",
      "         -1.7182e-01, -2.1485e-01, -2.5102e-01, -2.6103e-01, -2.8012e-01,\n",
      "         -2.5944e-01],\n",
      "        [ 6.8644e-04,  1.9017e-03,  4.1552e-03,  3.5199e-03,  1.2379e-03,\n",
      "          2.7792e-03,  6.6198e-03,  1.6995e-02,  2.8363e-02,  2.4145e-02,\n",
      "         -2.0244e-02, -6.8814e-02, -9.2394e-02, -6.2718e-02, -2.0566e-02,\n",
      "          5.4005e-02],\n",
      "        [ 3.6090e-04,  5.7232e-04,  1.2700e-03,  6.8418e-03,  9.5548e-03,\n",
      "          1.7195e-02,  2.8050e-02,  5.1774e-02,  6.7089e-02,  1.0692e-01,\n",
      "          1.7230e-01,  2.1846e-01,  2.3999e-01,  2.7347e-01,  3.7739e-01,\n",
      "          4.7877e-01]]) train_target0: tensor([1., 1., 1., 0., 0., 0., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1.])\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "\n",
    "train_dataset= StockDataset(\n",
    "  inputs_tensor_train,\n",
    "  targets_tensor_train\n",
    ")\n",
    "\n",
    "print(f\"train_dataset: {train_dataset[0]}\")\n",
    "\n",
    "train_dataloader= DataLoader(\n",
    "  dataset=train_dataset,\n",
    "  batch_size=BATCH_SIZE,\n",
    "  shuffle=False\n",
    ")\n",
    "\n",
    "train_input0, train_target0= next(iter(train_dataloader))\n",
    "print(f\"train_input0: {train_input0} train_target0: {train_target0}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "id": "cc3e3e58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_dataset: (tensor([ 0.0002,  0.0003,  0.0002, -0.0003, -0.0012, -0.0018, -0.0039, -0.0027,\n",
      "         0.0003, -0.0060, -0.0150, -0.0450, -0.0445, -0.0518, -0.0767, -0.1343]), tensor(1.))\n",
      "test_input0: tensor([[ 2.2565e-04,  3.1892e-04,  2.0579e-04, -3.0011e-04, -1.2484e-03,\n",
      "         -1.8275e-03, -3.8636e-03, -2.6572e-03,  2.6855e-04, -5.9798e-03,\n",
      "         -1.5003e-02, -4.4968e-02, -4.4510e-02, -5.1774e-02, -7.6663e-02,\n",
      "         -1.3426e-01],\n",
      "        [-1.0373e-03, -1.5457e-03,  2.8474e-04,  3.6381e-03,  6.2256e-03,\n",
      "          9.6730e-03,  1.5613e-02,  1.4329e-02,  1.6881e-03, -5.5279e-03,\n",
      "         -4.3219e-03,  7.8376e-03,  5.6513e-02,  1.0444e-01,  1.8568e-01,\n",
      "          2.4162e-01],\n",
      "        [ 6.9929e-16,  5.2447e-16,  1.7482e-16, -4.5454e-15, -5.2447e-16,\n",
      "          1.0435e-03,  4.0705e-03,  1.4180e-02,  2.7208e-02,  3.7461e-02,\n",
      "          3.8900e-02,  2.8943e-02,  3.4360e-02,  4.5564e-02,  1.0107e-01,\n",
      "          1.4545e-01],\n",
      "        [ 1.0379e-14,  9.8599e-15,  7.3035e-05, -5.4168e-03, -1.0108e-02,\n",
      "         -1.2038e-02, -1.5425e-02, -1.2891e-02, -1.4154e-02, -3.4468e-02,\n",
      "         -4.5034e-02, -3.3139e-02, -2.3185e-02, -3.3872e-02, -1.9174e-02,\n",
      "          1.0485e-03],\n",
      "        [-6.8367e-04, -6.7347e-04,  8.6122e-04,  2.2934e-03,  3.3846e-03,\n",
      "         -2.7998e-03, -7.9256e-03, -1.0663e-02, -1.8568e-02, -2.8721e-02,\n",
      "         -4.6812e-02, -6.0817e-02, -9.1547e-02, -8.6586e-02, -2.7259e-04,\n",
      "          1.0589e-01],\n",
      "        [ 1.4962e-03,  1.6519e-04,  1.1284e-03,  2.3730e-03, -1.3489e-04,\n",
      "         -2.8064e-03, -2.5435e-02, -4.6672e-02, -6.1632e-02, -9.2679e-02,\n",
      "         -1.2235e-01, -1.5584e-01, -2.1855e-01, -2.1014e-01, -2.3211e-01,\n",
      "         -1.9213e-01],\n",
      "        [ 3.5513e-03,  5.1429e-03,  2.7440e-02,  3.9983e-02,  4.8023e-02,\n",
      "          5.2923e-02,  5.6302e-02,  5.9041e-02,  6.0067e-02,  4.5163e-02,\n",
      "          6.7329e-02,  1.1454e-01,  1.6158e-01,  2.3947e-01,  2.9506e-01,\n",
      "          3.9359e-01],\n",
      "        [-2.6188e-04,  1.1036e-03,  1.2545e-04, -1.4250e-03, -1.3873e-03,\n",
      "          6.2344e-03,  2.1087e-02,  4.0155e-02,  2.1970e-02,  6.1408e-03,\n",
      "          2.0753e-02,  3.2959e-02,  1.2411e-01,  2.2103e-01,  1.4322e-01,\n",
      "          2.0945e-01],\n",
      "        [ 2.4955e-03,  5.0865e-03,  7.9201e-03,  3.2948e-02,  4.8069e-02,\n",
      "          6.3761e-02,  8.2820e-02,  9.0204e-02,  8.9736e-02,  7.2864e-02,\n",
      "          6.3451e-02, -5.6407e-03, -1.4726e-01, -2.8269e-01, -4.5387e-01,\n",
      "         -9.1833e-01],\n",
      "        [-2.7046e-03, -5.0225e-03, -3.8374e-03, -5.5216e-03, -9.3156e-03,\n",
      "         -1.2550e-02, -4.1023e-03, -2.1388e-03, -1.9016e-03, -1.5913e-02,\n",
      "         -5.9068e-02, -1.0620e-01, -1.6259e-01, -1.6671e-01, -1.6485e-01,\n",
      "         -2.6080e-01],\n",
      "        [-1.9966e-04, -1.5640e-03,  5.4574e-04,  2.4167e-03,  4.8226e-03,\n",
      "          6.9192e-03,  7.6248e-03,  7.5835e-03,  1.6737e-02,  1.9391e-02,\n",
      "          2.9898e-02,  4.3699e-02,  1.2348e-02, -4.2509e-02, -4.2128e-02,\n",
      "         -4.0666e-02],\n",
      "        [-9.5690e-04, -2.8513e-03, -5.3435e-03, -7.6800e-03, -8.6462e-03,\n",
      "         -8.9328e-03, -5.2420e-03,  4.1183e-04,  2.6821e-03,  2.4013e-03,\n",
      "          8.1255e-03,  5.9989e-03,  1.3949e-02,  9.1514e-02,  1.9237e-01,\n",
      "          3.1190e-01],\n",
      "        [ 1.2434e-14,  1.0057e-14, -3.2915e-15, -1.0972e-15, -3.6178e-03,\n",
      "         -1.3352e-02, -3.9164e-02, -6.7417e-02, -9.0596e-02, -9.6754e-02,\n",
      "         -9.5663e-02, -1.1542e-01, -7.3216e-02, -1.2557e-02,  1.2589e-02,\n",
      "          6.9942e-05],\n",
      "        [ 3.2607e-03,  3.2783e-03,  4.3898e-03,  6.7878e-03,  8.3250e-03,\n",
      "          9.2619e-03,  1.0082e-02,  1.2233e-02,  2.3367e-03,  6.2895e-03,\n",
      "          6.8047e-03,  3.7004e-02,  6.7262e-02,  2.2486e-02, -1.7650e-02,\n",
      "         -3.9595e-02],\n",
      "        [-1.0609e-03, -1.0104e-03, -5.7411e-03, -6.0473e-03, -5.7208e-03,\n",
      "         -4.8442e-03, -2.4852e-03, -9.4064e-03, -2.7283e-02, -4.6298e-02,\n",
      "         -4.2541e-02, -2.5024e-02, -2.2095e-02, -3.0111e-02, -1.3908e-02,\n",
      "          4.2306e-03],\n",
      "        [-4.6688e-04, -5.4158e-04, -1.7144e-03, -5.1870e-03, -6.1499e-03,\n",
      "         -3.5092e-03, -3.2511e-03, -1.2700e-02, -1.5862e-02, -1.8126e-02,\n",
      "         -3.3709e-02, -2.7015e-02, -2.9421e-02, -5.5061e-02, -8.9980e-02,\n",
      "         -1.5748e-01],\n",
      "        [-4.8724e-04, -1.4710e-03, -5.8747e-04, -4.3678e-04, -3.2276e-03,\n",
      "          1.1884e-02,  2.1707e-02,  3.3465e-02,  5.4052e-02,  7.0044e-02,\n",
      "          7.9378e-02,  8.3526e-02,  7.8713e-02,  9.2645e-02,  1.1848e-01,\n",
      "          9.0144e-02],\n",
      "        [-5.3238e-04, -5.3084e-03, -1.0032e-02, -1.4230e-02, -2.1213e-02,\n",
      "         -2.7781e-02, -3.3524e-02, -4.4704e-02, -6.2400e-02, -8.3358e-02,\n",
      "         -1.0651e-01, -1.4340e-01, -1.8825e-01, -2.1367e-01, -1.6175e-01,\n",
      "         -2.6760e-02],\n",
      "        [ 2.7738e-03,  1.0411e-03, -4.0464e-03, -8.5048e-03, -1.2042e-02,\n",
      "         -1.4758e-02, -3.4526e-02, -4.8353e-02, -5.9652e-02, -6.7558e-02,\n",
      "         -9.6844e-02, -1.1263e-01, -1.5399e-01, -2.0341e-01, -2.4918e-01,\n",
      "         -3.3269e-01],\n",
      "        [-1.4696e-03, -5.7150e-04,  4.5230e-03,  1.4571e-02,  2.2320e-02,\n",
      "          2.5936e-02,  2.9649e-02,  2.9487e-02,  2.5644e-02,  1.7846e-02,\n",
      "          2.6656e-02,  2.8196e-02,  5.8147e-02,  6.9110e-02,  2.1113e-02,\n",
      "          5.5935e-03],\n",
      "        [ 5.8840e-04,  2.4494e-03,  1.6557e-03, -1.0528e-03, -1.4384e-02,\n",
      "         -2.1384e-02, -2.6084e-02, -2.7806e-02, -2.6261e-02, -1.9558e-02,\n",
      "         -2.3988e-02, -1.7116e-02,  5.5029e-03,  1.9397e-02,  4.8036e-02,\n",
      "          9.0538e-02],\n",
      "        [-4.8377e-03, -6.4935e-05,  5.5383e-02,  8.9255e-02,  1.0658e-01,\n",
      "          1.1132e-01,  9.6970e-02,  5.7929e-02,  3.7160e-02,  3.4958e-02,\n",
      "          3.9448e-02,  4.8857e-02,  5.1523e-02,  1.3781e-03, -8.9316e-03,\n",
      "         -1.4417e-02],\n",
      "        [-4.3825e-03, -6.4428e-03, -2.7826e-03,  7.1336e-03,  1.1895e-02,\n",
      "          1.4798e-02,  6.2544e-03, -7.0289e-03, -2.3813e-02, -4.6205e-02,\n",
      "         -1.0467e-01, -9.9849e-02, -1.4819e-02,  7.6381e-02,  1.5152e-01,\n",
      "          2.1958e-01],\n",
      "        [ 4.5142e-05, -3.4308e-04, -6.7532e-04, -1.3588e-03, -3.2058e-03,\n",
      "         -2.5357e-03, -1.8811e-03,  9.0645e-04,  1.2344e-02,  2.6027e-02,\n",
      "          2.4856e-02,  5.9880e-03, -1.5984e-02, -5.0565e-02, -8.6849e-02,\n",
      "         -1.4326e-01],\n",
      "        [ 2.5547e-03,  3.3094e-03,  5.4335e-03,  7.9628e-03,  1.0131e-02,\n",
      "          1.1519e-02,  1.4923e-02,  2.4599e-02,  3.2005e-02,  3.0429e-02,\n",
      "          3.8043e-02,  5.4101e-02,  6.8626e-02,  1.1668e-01,  6.4702e-02,\n",
      "         -2.2575e-02],\n",
      "        [ 2.9975e-03,  3.2373e-03, -5.3865e-03, -1.3523e-02, -1.8850e-02,\n",
      "         -2.0269e-02, -2.8189e-02, -4.6993e-02, -5.5463e-02, -5.8729e-02,\n",
      "         -6.1567e-02, -4.8477e-02, -1.9339e-02, -1.4749e-02,  2.2072e-02,\n",
      "          1.1371e-02],\n",
      "        [ 9.5581e-04,  1.8981e-03,  2.5461e-03,  6.0094e-03,  9.2906e-03,\n",
      "          1.9631e-02,  2.5993e-02,  3.2674e-02,  3.6341e-02,  3.7120e-02,\n",
      "          3.9116e-02,  5.8470e-02,  9.1061e-02,  6.2913e-02,  2.1867e-02,\n",
      "          1.7224e-03],\n",
      "        [ 5.3232e-04,  1.2631e-03,  4.3959e-04,  4.4088e-03,  9.6742e-03,\n",
      "          1.2756e-02,  1.5912e-02,  2.1859e-02,  3.0565e-02,  5.7438e-02,\n",
      "          4.4036e-02,  4.4508e-02,  5.9871e-03, -1.2395e+00, -1.6943e+00,\n",
      "         -1.4992e+00],\n",
      "        [ 4.1711e-15,  5.6727e-15,  3.3369e-16,  6.4206e-04,  3.4341e-03,\n",
      "          5.4363e-03,  8.0198e-04, -4.7981e-03, -9.0170e-03, -2.5753e-02,\n",
      "         -5.7539e-02, -6.3145e-02, -5.0001e-02, -4.6974e-02, -1.6929e-02,\n",
      "         -1.8425e-02],\n",
      "        [ 5.2552e-03,  8.0098e-03,  1.1648e-02,  9.4643e-03,  5.4251e-03,\n",
      "          3.6293e-03, -2.6866e-02, -7.1341e-02, -1.0489e-01, -1.4255e-01,\n",
      "         -1.7182e-01, -2.1485e-01, -2.5102e-01, -2.6103e-01, -2.8012e-01,\n",
      "         -2.5944e-01],\n",
      "        [ 6.8644e-04,  1.9017e-03,  4.1552e-03,  3.5199e-03,  1.2379e-03,\n",
      "          2.7792e-03,  6.6198e-03,  1.6995e-02,  2.8363e-02,  2.4145e-02,\n",
      "         -2.0244e-02, -6.8814e-02, -9.2394e-02, -6.2718e-02, -2.0566e-02,\n",
      "          5.4005e-02],\n",
      "        [ 3.6090e-04,  5.7232e-04,  1.2700e-03,  6.8418e-03,  9.5548e-03,\n",
      "          1.7195e-02,  2.8050e-02,  5.1774e-02,  6.7089e-02,  1.0692e-01,\n",
      "          1.7230e-01,  2.1846e-01,  2.3999e-01,  2.7347e-01,  3.7739e-01,\n",
      "          4.7877e-01]]) test_target0: tensor([0., 0., 1., 1., 0., 0., 0., 0., 1., 1., 1., 0., 0., 0., 0., 0., 1., 1.,\n",
      "        0., 0., 1., 0., 1., 0., 0., 0., 0., 1., 1., 1., 0., 0.])\n"
     ]
    }
   ],
   "source": [
    "test_dataset= StockDataset(\n",
    "  inputs_tensor_test,\n",
    "  targets_tensor_test\n",
    ")\n",
    "\n",
    "print(f\"train_dataset: {train_dataset[0]}\")\n",
    "\n",
    "val_dataloader= DataLoader(\n",
    "  dataset=test_dataset,\n",
    "  batch_size=BATCH_SIZE,\n",
    "  shuffle=False\n",
    ")\n",
    "\n",
    "test_input0, test_target0= next(iter(val_dataloader))\n",
    "print(f\"test_input0: {train_input0} test_target0: {test_target0}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "id": "dd01423f-68e8-434f-8b20-bb0583bade18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXECUTE FROM THIS STEP To CREATE A NETWORK WITH RANDOM WEIGHTS\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "class StockModelBinaryV0(nn.Module):\n",
    "  def __init__(self, input_features, hidden_units):\n",
    "    \"\"\"Initializes multi-class classification model\"\"\"\n",
    "    super().__init__()\n",
    "    self.linear_layer_stack = nn.Sequential(\n",
    "      nn.Linear(in_features=input_features, out_features=hidden_units*16),\n",
    "      nn.LeakyReLU(negative_slope=0.1),\n",
    "      nn.Linear(in_features=hidden_units*16, out_features=hidden_units*8),\n",
    "      nn.LeakyReLU(negative_slope=0.1),\n",
    "      nn.Linear(in_features=hidden_units*8, out_features=hidden_units*4),\n",
    "      nn.LeakyReLU(negative_slope=0.1),\n",
    "      nn.Linear(in_features=hidden_units*4, out_features=hidden_units),\n",
    "      nn.LeakyReLU(negative_slope=0.1),\n",
    "      nn.Linear(in_features=hidden_units, out_features=1)\n",
    "    )\n",
    "\n",
    "  def forward(self, x):\n",
    "    # print(\"forward x: \",\", \".join([str(num) for num in x.tolist()]))\n",
    "    # Layers are defined inside the Sequencial NN and will be applied here.\n",
    "    return self.linear_layer_stack(x)\n",
    "\n",
    "# Create an instance of the model\n",
    "model_0 = StockModelBinaryV0(\n",
    "  input_features=len(signal_avg),\n",
    "  hidden_units=HIDDEN_UNITS).to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "id": "293a691f-abc2-40a4-99d9-d6b705e9257d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train positive cases: 13212 class_weights: tensor([0.3312, 0.6688])\n"
     ]
    }
   ],
   "source": [
    "import torchmetrics\n",
    "\n",
    "# loss_fn = nn.BCEWithLogitsLoss()\n",
    "\n",
    "# Loss function for an imbalanced dataset (there many more 0's than 1's). Apply more weight to the less frequent class\n",
    "num_ones = torch.count_nonzero(targets_tensor_train)\n",
    "num_samples = [len(targets_tensor_train)-num_ones, num_ones]\n",
    "class_weights = 1.0 / torch.tensor(num_samples, dtype=torch.float32)\n",
    "class_weights = class_weights / torch.sum(class_weights)\n",
    "print(f\"Train positive cases: {num_ones} class_weights: {class_weights}\")\n",
    "\n",
    "loss_fn = nn.BCEWithLogitsLoss(pos_weight=class_weights[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "id": "98e5eb2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "###################\n",
    "##### SET PARAMETERS\n",
    "###################\n",
    "# PERFORMANCE_MEASURE=\"accu\"\n",
    "# performance_fn= torchmetrics.Accuracy(task='binary').to(device)\n",
    "PERFORMANCE_MEASURE=\"prec\"\n",
    "performance_fn= torchmetrics.Precision(task='binary').to(device)\n",
    "# PERFORMANCE_MEASURE=\"reca\"\n",
    "# performance_fn= torchmetrics.Recall(task='binary').to(device)\n",
    "###################\n",
    "##### SET PARAMETERS\n",
    "###################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "id": "ef281180",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Should you reset BEST PERFORMANCE\n",
    "best_val_performance = 0\n",
    "model_best = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "id": "8adf8712",
   "metadata": {},
   "outputs": [],
   "source": [
    "###################\n",
    "##### SET PARAMETERS\n",
    "###################\n",
    "# DO: AFTER THIS CELL RUNS EXECUTE CELLS UNTIL SAVE STEP TO KEEP BEST RESULT IN CASE IT GOES DOWN\n",
    "#    lr = 0.1 -> 0.03 -> 0.001\n",
    "#    epochs 200 + 200 (lr=0.1) -> 100 (lr=0.03) -> 100 (lr=0.001)\n",
    "# EXECUTE 0.1 x 200 for 2 TIMES (or 400 for 1 time)\n",
    "# optimizer = torch.optim.SGD(params=model_0.parameters(), lr=0.1)\n",
    "# epochs=400\n",
    "# optimizer = torch.optim.SGD(params=model_0.parameters(), lr=0.03)\n",
    "# epochs=100\n",
    "# optimizer = torch.optim.SGD(params=model_0.parameters(), lr=0.005)\n",
    "# epochs=100\n",
    "# optimizer = torch.optim.SGD(params=model_0.parameters(), lr=0.0007)\n",
    "# epochs=100\n",
    "# optimizer = torch.optim.SGD(params=model_0.parameters(), lr=0.0001)\n",
    "# epochs=100\n",
    "###Using Adam optimizer\n",
    "# learning_rate = 0.005\n",
    "# beta_1 = 0.9\n",
    "# beta_2 = 0.999\n",
    "# decay = 0.01\n",
    "# optimizer = optim.Adam(params=model_0.parameters(), lr=learning_rate, betas=(beta_1, beta_2), eps=1e-8, weight_decay=decay)\n",
    "# epochs=2000\n",
    "\n",
    "EPOCHS=1000\n",
    "LEARNING_RATE= 0.1\n",
    "optimizer = torch.optim.SGD(params=model_0.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "##### Using a StepLR Scheduler\n",
    "# from torch.optim.lr_scheduler import StepLR\n",
    "# gamma = 0.95\n",
    "# scheduler = StepLR(optimizer, step_size=20, gamma=gamma)\n",
    "## If continue optimization\n",
    "# learning_rate_last= 0.0080995 * 0.95\n",
    "# gamma = 0.95\n",
    "# optimizer = torch.optim.SGD(params=model_0.parameters(), lr=learning_rate_last*gamma)\n",
    "# scheduler = StepLR(optimizer, step_size=20, gamma=gamma)\n",
    "# epochs= 200\n",
    "\n",
    "##### Using a ReduceLROnPlateau\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=10)\n",
    "###################\n",
    "##### SET PARAMETERS\n",
    "###################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "id": "b8757655-3fc1-4b53-93da-5bb94f4ed651",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 lr: 0.1000000 | Loss: 0.50129 prec: 0.0000% | Val loss: 0.49628 Val prec: 0.0000%\n",
      "Epoch: 11 lr: 0.1000000 | Loss: 0.31796 prec: 91.1222% | Val loss: 0.33173 Val prec: 84.9215%\n",
      "Epoch: 21 lr: 0.1000000 | Loss: 0.26959 prec: 94.3211% | Val loss: 0.30956 Val prec: 86.7785%\n",
      "Epoch: 31 lr: 0.1000000 | Loss: 0.20041 prec: 95.5864% | Val loss: 0.20151 Val prec: 91.0158%\n",
      "Epoch: 41 lr: 0.1000000 | Loss: 0.13614 prec: 96.8443% | Val loss: 0.14007 Val prec: 96.0154%\n",
      "Epoch: 51 lr: 0.1000000 | Loss: 0.12082 prec: 97.5455% | Val loss: 0.09962 Val prec: 98.4240%\n",
      "Epoch: 61 lr: 0.1000000 | Loss: 0.07560 prec: 98.0763% | Val loss: 0.06687 Val prec: 98.6022%\n",
      "Epoch: 71 lr: 0.1000000 | Loss: 0.05767 prec: 98.6049% | Val loss: 0.05283 Val prec: 98.6176%\n",
      "Epoch: 81 lr: 0.1000000 | Loss: 0.04875 prec: 98.6414% | Val loss: 0.05260 Val prec: 98.7343%\n",
      "Epoch: 91 lr: 0.1000000 | Loss: 0.03826 prec: 99.0400% | Val loss: 0.04466 Val prec: 98.4238%\n",
      "Epoch: 101 lr: 0.1000000 | Loss: 0.03320 prec: 99.1883% | Val loss: 0.02694 Val prec: 99.6468%\n",
      "Epoch: 111 lr: 0.1000000 | Loss: 0.03036 prec: 99.1798% | Val loss: 0.03445 Val prec: 99.1081%\n",
      "Epoch: 121 lr: 0.0100000 | Loss: 0.01177 prec: 99.8427% | Val loss: 0.01309 Val prec: 99.8026%\n",
      "Epoch: 131 lr: 0.0100000 | Loss: 0.00671 prec: 99.9745% | Val loss: 0.00958 Val prec: 99.9398%\n",
      "Epoch: 141 lr: 0.0100000 | Loss: 0.00597 prec: 99.9718% | Val loss: 0.00871 Val prec: 99.9398%\n",
      "Epoch: 151 lr: 0.0100000 | Loss: 0.00560 prec: 99.9515% | Val loss: 0.00815 Val prec: 99.9398%\n",
      "Epoch: 161 lr: 0.0100000 | Loss: 0.00535 prec: 99.9515% | Val loss: 0.00788 Val prec: 100.0000%\n",
      "Epoch: 171 lr: 0.0100000 | Loss: 0.00516 prec: 99.9522% | Val loss: 0.00792 Val prec: 99.9344%\n",
      "Epoch: 181 lr: 0.0010000 | Loss: 0.00394 prec: 99.9858% | Val loss: 0.00737 Val prec: 100.0000%\n",
      "Epoch: 191 lr: 0.0010000 | Loss: 0.00390 prec: 99.9858% | Val loss: 0.00733 Val prec: 100.0000%\n",
      "Epoch: 201 lr: 0.0010000 | Loss: 0.00386 prec: 99.9858% | Val loss: 0.00730 Val prec: 100.0000%\n",
      "Epoch: 211 lr: 0.0010000 | Loss: 0.00383 prec: 99.9938% | Val loss: 0.00727 Val prec: 100.0000%\n",
      "Epoch: 221 lr: 0.0010000 | Loss: 0.00381 prec: 99.9938% | Val loss: 0.00725 Val prec: 100.0000%\n",
      "Epoch: 231 lr: 0.0010000 | Loss: 0.00378 prec: 99.9938% | Val loss: 0.00721 Val prec: 100.0000%\n",
      "Epoch: 241 lr: 0.0010000 | Loss: 0.00375 prec: 99.9938% | Val loss: 0.00719 Val prec: 100.0000%\n",
      "Epoch: 251 lr: 0.0010000 | Loss: 0.00373 prec: 99.9938% | Val loss: 0.00717 Val prec: 100.0000%\n",
      "Epoch: 261 lr: 0.0010000 | Loss: 0.00370 prec: 99.9938% | Val loss: 0.00715 Val prec: 100.0000%\n",
      "Epoch: 271 lr: 0.0010000 | Loss: 0.00368 prec: 99.9938% | Val loss: 0.00713 Val prec: 100.0000%\n",
      "Epoch: 281 lr: 0.0010000 | Loss: 0.00366 prec: 99.9938% | Val loss: 0.00709 Val prec: 100.0000%\n",
      "Epoch: 291 lr: 0.0010000 | Loss: 0.00363 prec: 99.9938% | Val loss: 0.00706 Val prec: 100.0000%\n",
      "Epoch: 301 lr: 0.0010000 | Loss: 0.00361 prec: 99.9938% | Val loss: 0.00705 Val prec: 100.0000%\n",
      "Epoch: 311 lr: 0.0010000 | Loss: 0.00359 prec: 99.9938% | Val loss: 0.00702 Val prec: 100.0000%\n",
      "Epoch: 321 lr: 0.0010000 | Loss: 0.00357 prec: 99.9938% | Val loss: 0.00702 Val prec: 100.0000%\n",
      "Epoch: 331 lr: 0.0010000 | Loss: 0.00356 prec: 99.9938% | Val loss: 0.00700 Val prec: 100.0000%\n",
      "Epoch: 341 lr: 0.0010000 | Loss: 0.00354 prec: 99.9938% | Val loss: 0.00698 Val prec: 100.0000%\n",
      "Epoch: 351 lr: 0.0010000 | Loss: 0.00352 prec: 99.9938% | Val loss: 0.00696 Val prec: 100.0000%\n",
      "Epoch: 361 lr: 0.0010000 | Loss: 0.00350 prec: 99.9938% | Val loss: 0.00694 Val prec: 100.0000%\n",
      "Epoch: 371 lr: 0.0010000 | Loss: 0.00349 prec: 99.9938% | Val loss: 0.00692 Val prec: 100.0000%\n",
      "Epoch: 381 lr: 0.0010000 | Loss: 0.00347 prec: 99.9938% | Val loss: 0.00690 Val prec: 100.0000%\n",
      "Epoch: 391 lr: 0.0010000 | Loss: 0.00345 prec: 99.9938% | Val loss: 0.00689 Val prec: 100.0000%\n",
      "Epoch: 401 lr: 0.0010000 | Loss: 0.00344 prec: 99.9938% | Val loss: 0.00688 Val prec: 100.0000%\n",
      "Epoch: 411 lr: 0.0010000 | Loss: 0.00342 prec: 99.9938% | Val loss: 0.00686 Val prec: 100.0000%\n",
      "Epoch: 421 lr: 0.0010000 | Loss: 0.00340 prec: 99.9938% | Val loss: 0.00685 Val prec: 100.0000%\n",
      "Epoch: 431 lr: 0.0010000 | Loss: 0.00339 prec: 99.9938% | Val loss: 0.00683 Val prec: 100.0000%\n",
      "Epoch: 441 lr: 0.0010000 | Loss: 0.00337 prec: 99.9938% | Val loss: 0.00682 Val prec: 100.0000%\n",
      "Epoch: 451 lr: 0.0010000 | Loss: 0.00335 prec: 99.9938% | Val loss: 0.00678 Val prec: 100.0000%\n",
      "Epoch: 461 lr: 0.0010000 | Loss: 0.00334 prec: 99.9938% | Val loss: 0.00676 Val prec: 100.0000%\n",
      "Epoch: 471 lr: 0.0010000 | Loss: 0.00332 prec: 99.9938% | Val loss: 0.00674 Val prec: 100.0000%\n",
      "Epoch: 481 lr: 0.0010000 | Loss: 0.00331 prec: 99.9938% | Val loss: 0.00671 Val prec: 100.0000%\n",
      "Epoch: 491 lr: 0.0010000 | Loss: 0.00329 prec: 99.9938% | Val loss: 0.00671 Val prec: 100.0000%\n",
      "Epoch: 501 lr: 0.0010000 | Loss: 0.00328 prec: 99.9938% | Val loss: 0.00669 Val prec: 100.0000%\n",
      "Epoch: 511 lr: 0.0010000 | Loss: 0.00327 prec: 99.9938% | Val loss: 0.00668 Val prec: 100.0000%\n",
      "Epoch: 521 lr: 0.0010000 | Loss: 0.00325 prec: 99.9938% | Val loss: 0.00666 Val prec: 100.0000%\n",
      "Epoch: 531 lr: 0.0010000 | Loss: 0.00324 prec: 99.9938% | Val loss: 0.00666 Val prec: 100.0000%\n",
      "Epoch: 541 lr: 0.0010000 | Loss: 0.00322 prec: 99.9938% | Val loss: 0.00663 Val prec: 100.0000%\n",
      "Epoch: 551 lr: 0.0010000 | Loss: 0.00321 prec: 99.9938% | Val loss: 0.00662 Val prec: 100.0000%\n",
      "Epoch: 561 lr: 0.0010000 | Loss: 0.00320 prec: 99.9938% | Val loss: 0.00660 Val prec: 100.0000%\n",
      "Epoch: 571 lr: 0.0010000 | Loss: 0.00318 prec: 99.9938% | Val loss: 0.00659 Val prec: 100.0000%\n",
      "Epoch: 581 lr: 0.0010000 | Loss: 0.00317 prec: 99.9938% | Val loss: 0.00658 Val prec: 100.0000%\n",
      "Epoch: 591 lr: 0.0010000 | Loss: 0.00316 prec: 99.9938% | Val loss: 0.00657 Val prec: 100.0000%\n",
      "Epoch: 601 lr: 0.0010000 | Loss: 0.00315 prec: 99.9938% | Val loss: 0.00656 Val prec: 100.0000%\n",
      "Epoch: 611 lr: 0.0010000 | Loss: 0.00314 prec: 99.9938% | Val loss: 0.00656 Val prec: 100.0000%\n",
      "Epoch: 621 lr: 0.0010000 | Loss: 0.00312 prec: 99.9938% | Val loss: 0.00654 Val prec: 100.0000%\n",
      "Epoch: 631 lr: 0.0010000 | Loss: 0.00311 prec: 99.9938% | Val loss: 0.00653 Val prec: 100.0000%\n",
      "Epoch: 641 lr: 0.0010000 | Loss: 0.00310 prec: 99.9938% | Val loss: 0.00652 Val prec: 100.0000%\n",
      "Epoch: 651 lr: 0.0010000 | Loss: 0.00309 prec: 99.9938% | Val loss: 0.00650 Val prec: 100.0000%\n",
      "Epoch: 661 lr: 0.0010000 | Loss: 0.00308 prec: 99.9938% | Val loss: 0.00649 Val prec: 100.0000%\n",
      "Epoch: 671 lr: 0.0010000 | Loss: 0.00307 prec: 99.9938% | Val loss: 0.00648 Val prec: 100.0000%\n",
      "Epoch: 681 lr: 0.0010000 | Loss: 0.00306 prec: 99.9938% | Val loss: 0.00647 Val prec: 100.0000%\n",
      "Epoch: 691 lr: 0.0010000 | Loss: 0.00305 prec: 99.9938% | Val loss: 0.00646 Val prec: 100.0000%\n",
      "Epoch: 701 lr: 0.0010000 | Loss: 0.00303 prec: 99.9938% | Val loss: 0.00646 Val prec: 100.0000%\n",
      "Epoch: 711 lr: 0.0010000 | Loss: 0.00302 prec: 99.9938% | Val loss: 0.00644 Val prec: 100.0000%\n",
      "Epoch: 721 lr: 0.0010000 | Loss: 0.00301 prec: 99.9938% | Val loss: 0.00643 Val prec: 100.0000%\n",
      "Epoch: 731 lr: 0.0010000 | Loss: 0.00299 prec: 99.9938% | Val loss: 0.00642 Val prec: 100.0000%\n",
      "Epoch: 741 lr: 0.0010000 | Loss: 0.00298 prec: 99.9938% | Val loss: 0.00641 Val prec: 100.0000%\n",
      "Epoch: 751 lr: 0.0010000 | Loss: 0.00297 prec: 99.9938% | Val loss: 0.00640 Val prec: 100.0000%\n",
      "Epoch: 761 lr: 0.0010000 | Loss: 0.00296 prec: 99.9938% | Val loss: 0.00638 Val prec: 100.0000%\n",
      "Epoch: 771 lr: 0.0010000 | Loss: 0.00295 prec: 99.9938% | Val loss: 0.00638 Val prec: 100.0000%\n",
      "Epoch: 781 lr: 0.0010000 | Loss: 0.00294 prec: 99.9938% | Val loss: 0.00638 Val prec: 100.0000%\n",
      "Epoch: 791 lr: 0.0010000 | Loss: 0.00293 prec: 99.9938% | Val loss: 0.00636 Val prec: 100.0000%\n",
      "Epoch: 801 lr: 0.0010000 | Loss: 0.00292 prec: 99.9938% | Val loss: 0.00635 Val prec: 100.0000%\n",
      "Epoch: 811 lr: 0.0010000 | Loss: 0.00291 prec: 99.9938% | Val loss: 0.00633 Val prec: 100.0000%\n",
      "Epoch: 821 lr: 0.0010000 | Loss: 0.00290 prec: 99.9938% | Val loss: 0.00633 Val prec: 100.0000%\n",
      "Epoch: 831 lr: 0.0010000 | Loss: 0.00289 prec: 99.9938% | Val loss: 0.00631 Val prec: 100.0000%\n",
      "Epoch: 841 lr: 0.0010000 | Loss: 0.00288 prec: 99.9938% | Val loss: 0.00630 Val prec: 100.0000%\n",
      "Epoch: 851 lr: 0.0010000 | Loss: 0.00287 prec: 99.9938% | Val loss: 0.00630 Val prec: 100.0000%\n",
      "Epoch: 861 lr: 0.0010000 | Loss: 0.00287 prec: 99.9938% | Val loss: 0.00628 Val prec: 100.0000%\n",
      "Epoch: 871 lr: 0.0010000 | Loss: 0.00286 prec: 99.9938% | Val loss: 0.00627 Val prec: 100.0000%\n",
      "Epoch: 881 lr: 0.0010000 | Loss: 0.00285 prec: 99.9938% | Val loss: 0.00626 Val prec: 100.0000%\n",
      "Epoch: 891 lr: 0.0010000 | Loss: 0.00284 prec: 99.9938% | Val loss: 0.00626 Val prec: 100.0000%\n",
      "Epoch: 901 lr: 0.0010000 | Loss: 0.00283 prec: 99.9938% | Val loss: 0.00625 Val prec: 100.0000%\n",
      "Epoch: 911 lr: 0.0010000 | Loss: 0.00282 prec: 99.9938% | Val loss: 0.00624 Val prec: 100.0000%\n",
      "Epoch: 921 lr: 0.0010000 | Loss: 0.00282 prec: 99.9938% | Val loss: 0.00622 Val prec: 100.0000%\n",
      "Epoch: 931 lr: 0.0010000 | Loss: 0.00281 prec: 99.9938% | Val loss: 0.00622 Val prec: 100.0000%\n",
      "Epoch: 941 lr: 0.0010000 | Loss: 0.00280 prec: 99.9938% | Val loss: 0.00621 Val prec: 100.0000%\n",
      "Epoch: 951 lr: 0.0010000 | Loss: 0.00279 prec: 99.9938% | Val loss: 0.00620 Val prec: 100.0000%\n",
      "Epoch: 961 lr: 0.0010000 | Loss: 0.00278 prec: 99.9938% | Val loss: 0.00619 Val prec: 100.0000%\n",
      "Epoch: 971 lr: 0.0010000 | Loss: 0.00278 prec: 99.9938% | Val loss: 0.00618 Val prec: 100.0000%\n",
      "Epoch: 981 lr: 0.0010000 | Loss: 0.00277 prec: 99.9938% | Val loss: 0.00618 Val prec: 100.0000%\n",
      "Epoch: 991 lr: 0.0010000 | Loss: 0.00276 prec: 99.9938% | Val loss: 0.00617 Val prec: 100.0000%\n",
      "Finished: Epoch: 1000 lr: 0.0010000 | Loss: 0.00275 prec: 99.9938% | Val loss: 0.00616 Val prec: 100.0000%\n"
     ]
    }
   ],
   "source": [
    "from copy import deepcopy\n",
    "\n",
    "EARLY_STOPPING_PATIENCE = 50\n",
    "\n",
    "best_val_loss = float('inf')\n",
    "early_stopping_counter = 0\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    train_loss, train_performance= 0, 0\n",
    "    train_samples = 0\n",
    "\n",
    "    # Training\n",
    "    model_0.train()\n",
    "\n",
    "    for batch, (X, y) in enumerate(train_dataloader):\n",
    "        X= X.to(device)\n",
    "        y= y.to(device)\n",
    "\n",
    "        # Forward pass\n",
    "        y_logits= model_0(X).view(-1)\n",
    "        \n",
    "        # turn logits -> prediction probabilities -> prediction labels\n",
    "        y_sigmoid_output = torch.sigmoid(y_logits)\n",
    "        y_pred = (y_sigmoid_output > TRAINING_THRESHOLD).float()\n",
    "        \n",
    "        # Calculate loss and accuracy\n",
    "        loss= loss_fn(y_logits, y)\n",
    "        train_loss+= loss * X.size(0)\n",
    "        train_performance+= performance_fn(y_pred, y) * X.size(0)\n",
    "        train_samples += X.size(0)\n",
    "        \n",
    "        # Zero the gradients to avoid accomulating gradients from previous iteration\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Backpropagation\n",
    "        loss.backward()\n",
    "        \n",
    "        # Updates the model usign the gradients\n",
    "        optimizer.step()\n",
    "    \n",
    "    train_loss /= train_samples\n",
    "    train_performance /= train_samples\n",
    "      \n",
    "    model_0.eval()\n",
    "    val_loss, val_performance= 0, 0\n",
    "    val_samples = 0\n",
    "    with torch.inference_mode():\n",
    "        for X, y in val_dataloader:\n",
    "            X= X.to(device)\n",
    "            y= y.to(device)\n",
    "        \n",
    "            # Predict for test data\n",
    "            val_logits= model_0(X).view(-1)\n",
    "            sigmoid_output = torch.sigmoid(val_logits)\n",
    "            val_pred = (sigmoid_output > TRAINING_THRESHOLD).float()\n",
    "            \n",
    "            # Calculate test loss/accuracy\n",
    "            val_loss+= loss_fn(val_logits, y) * X.size(0)\n",
    "            val_performance+= performance_fn(val_pred, y) * X.size(0)\n",
    "            val_samples += X.size(0)\n",
    "\n",
    "        val_loss /= val_samples\n",
    "        val_performance /= val_samples\n",
    "    \n",
    "    # Update the learning rate\n",
    "    scheduler.step(val_loss)\n",
    "\n",
    "    if epoch % 10 == 0:\n",
    "      print(f\"Epoch: {epoch+1} lr: {optimizer.param_groups[0]['lr']:.7f} | Loss: {train_loss:.5f} {PERFORMANCE_MEASURE}: {train_performance*100:.4f}% | Val loss: {val_loss:.5f} Val {PERFORMANCE_MEASURE}: {val_performance*100:.4f}%\")\n",
    "\n",
    "    # Early stopping\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        early_stopping_counter = 0\n",
    "        model_best = deepcopy(model_0)\n",
    "    else:\n",
    "        early_stopping_counter += 1\n",
    "        if early_stopping_counter >= EARLY_STOPPING_PATIENCE:\n",
    "            print(\"Early stopping triggered.\")\n",
    "            break    \n",
    "\n",
    "print(f\"Finished: Epoch: {epoch+1} lr: {optimizer.param_groups[0]['lr']:.7f} | Loss: {train_loss:.5f} {PERFORMANCE_MEASURE}: {train_performance*100:.4f}% | Val loss: {val_loss:.5f} Val {PERFORMANCE_MEASURE}: {val_performance*100:.4f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "id": "d5fc3e0a-5ab5-4a72-a744-0d465dcbec94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss: 0.00798 Performance prec: 100.0000000%\n",
      "Train validation confusion matrix:\n",
      "tensor([[2983,    0],\n",
      "        [  26, 1424]])\n",
      "Train validation accuracy: 99.41%\n",
      "Train validation precision: 100.00%\n",
      "Train validation false_positives: 0 true_positives: 1424\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x700 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from torchmetrics import ConfusionMatrix, Accuracy, Precision\n",
    "from mlxtend.plotting import plot_confusion_matrix\n",
    "\n",
    "model_best.eval()\n",
    "val_loss, val_performance= 0, 0\n",
    "with torch.inference_mode():\n",
    "    X= inputs_tensor_test.to(device)\n",
    "    y= targets_tensor_test.to(device)\n",
    "\n",
    "    # Predict for validation data\n",
    "    val_logits= model_best(X).view(-1)\n",
    "    sigmoid_output = torch.sigmoid(val_logits)\n",
    "    val_pred = (sigmoid_output > TRAINING_THRESHOLD).float()\n",
    "    \n",
    "    # Calculate loss/performance(accuracy|precision)\n",
    "    val_loss+= loss_fn(val_logits, y)\n",
    "    val_performance+= performance_fn(val_pred, y)\n",
    "\n",
    "print(f\"Validation loss: {val_loss:.5f} Performance {PERFORMANCE_MEASURE}: {val_performance*100:.7f}%\")\n",
    "\n",
    "confmat= ConfusionMatrix(task='binary')\n",
    "\n",
    "# test_data.targets are the values we want to predict in the test dataloader\n",
    "confmat_tensor= confmat(\n",
    "  preds= val_pred.cpu(),\n",
    "  target= targets_tensor_test.cpu())\n",
    "\n",
    "# Plot confusion matrix\n",
    "fig, ax= plot_confusion_matrix(\n",
    "  conf_mat= confmat_tensor.numpy(),\n",
    "  figsize= (10, 7)\n",
    ")\n",
    "\n",
    "accuracy_fn= Accuracy(task='binary').to(device)\n",
    "val_accuracy = accuracy_fn(val_pred, y)\n",
    "print(f\"Train validation confusion matrix:\\n{confmat_tensor}\")\n",
    "\n",
    "precision_fn= Precision(task='binary').to(device)\n",
    "val_precision = precision_fn(val_pred, y)\n",
    "print(f\"Train validation accuracy: {val_accuracy*100:.2f}%\")\n",
    "print(f\"Train validation precision: {val_precision*100:.2f}%\")\n",
    "false_positives = confmat_tensor[0, 1].item()\n",
    "true_positives = confmat_tensor[1, 1].item()\n",
    "print(f\"Train validation false_positives: {false_positives} true_positives: {true_positives}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "id": "32a36498-a273-4bcf-872c-3fa55e8deb92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trained model saved: 2024-05-17-1646-TSLA-predictUP-dates20170101-20240101-days15-down500-up700-in16-hid12-pos_weight6688pct-prec9958pct-fp6tp1435-model-best.pth\n"
     ]
    }
   ],
   "source": [
    "# Saves model.state_dic() with best performance to a file\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "# Create directory, if it doesn't exist, to store models\n",
    "MODEL_PATH= Path(\"models\")\n",
    "MODEL_PATH.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "target= \"UP\" if INDEX_KEEP > 1 else \"DOWN\"\n",
    "\n",
    "# Create path to the model\n",
    "MODEL_NAME= f\"{datetime.now().strftime('%Y-%m-%d-%H%M')}-{TICKER}-predict{target}-dates20170101-20240101-days{DAYS_PREDICT}-down{int(DOWN_PCTS_PREDICT[0]*100)}-up{int(UP_PCTS_PREDICT[0]*100)}-in{len(signal_avg)}-hid{HIDDEN_UNITS}-pos_weight{class_weights[1]*10000:.0f}pct-{PERFORMANCE_MEASURE}{val_performance*10000:.0f}pct-fp{false_positives}tp{true_positives}-model-best.pth\"\n",
    "MODEL_SAVE_PATH = MODEL_PATH / MODEL_NAME\n",
    "\n",
    "# torch.save(\n",
    "#   obj=model_0.state_dict(),\n",
    "#   f=f\"{MODEL_SAVE_PATH}.pth\")\n",
    "\n",
    "torch.save(\n",
    "    obj=model_best.state_dict(), \n",
    "    f=f\"{MODEL_SAVE_PATH}\")\n",
    "\n",
    "\n",
    "print(f\"Trained model saved: {MODEL_NAME}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b121c6be",
   "metadata": {},
   "source": [
    "#### Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "id": "c0e8cb4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ticker: TSLA interval: 15\n",
      "Averages: [2, 3, 5, 8, 13, 21, 34, 55, 89, 144, 233, 377, 610, 987, 1597, 2584]\n",
      "Train predict UP - days: 15 down: [5.0] up: [7.0]\n",
      "Data start: 2017-01-03 09:30:00-05:00 end: 2023-12-29 15:45:00-05:00\n",
      "Input data frequencies:\n",
      "Total: 44321\n",
      " 35.61%  15784 times -5.0% change (0)\n",
      " 31.31%  13875 times   0% change (1)\n",
      " 33.08%  14662 times 7.0% change (2)\n",
      "Training dataset frequencies:\n",
      "Total: 39888\n",
      " 66.88%  26676 times (0.0)\n",
      " 33.12%  13212 times (1.0)\n",
      "Validation dataset frequencies:\n",
      "Total: 4433\n",
      " 67.29%   2983 times (0.0)\n",
      " 32.71%   1450 times (1.0)\n",
      "Train positive cases: 13212 class_weights: tensor([0.3312, 0.6688])\n",
      "--Training\n",
      "Train/Val split: 0.9\n",
      "Network hidden units: 12\n",
      "Train threshold: 0.7\n",
      "Epochs: 1000 learning_rate: 0.1\n",
      "Optimizer: SGD Scheduler: ReduceLROnPlateau\n",
      "--Results\n",
      "Validation loss: 0.00798 Performance prec: 100.00%\n",
      "Train validation confusion matrix:\n",
      "tensor([[2983,    0],\n",
      "        [  26, 1424]])\n",
      "Train validation accuracy: 99.41%\n",
      "Train validation precision: 100.00%\n",
      "Train validation false_positives: 0 true_positives: 1424\n",
      "Trained model: 2024-05-17-1646-TSLA-predictUP-dates20170101-20240101-days15-down500-up700-in16-hid12-pos_weight6688pct-prec9958pct-fp6tp1435-model-best.pth\n"
     ]
    }
   ],
   "source": [
    "print(f\"Ticker: {TICKER} interval: {DATA_INTERVAL_MINUTES}\")\n",
    "print(f\"Averages: {signal_avg}\")\n",
    "print(f\"Train predict {'UP' if INDEX_KEEP > 1 else 'DOWN'} - days: {DAYS_PREDICT} down: {DOWN_PCTS_PREDICT} up: {UP_PCTS_PREDICT}\")\n",
    "\n",
    "print(f\"Data start: {df['date'][0]} end: {df['date'].iloc[-1]}\")\n",
    "print(\"Input data frequencies:\")\n",
    "lu.display_frequency_classes(targets_clean, DOWN_PCTS_PREDICT, UP_PCTS_PREDICT)\n",
    "\n",
    "print(\"Training dataset frequencies:\")\n",
    "lu.display_frequency_values(targets_tensor_train.tolist())\n",
    "print(\"Validation dataset frequencies:\")\n",
    "lu.display_frequency_values(targets_tensor_test.tolist())\n",
    "\n",
    "print(f\"Train positive cases: {num_ones} class_weights: {class_weights}\")\n",
    "\n",
    "print(\"--Training\")\n",
    "print(f\"Train/Val split: {TRAIN_SPLIT}\")\n",
    "print(f\"Network hidden units: {HIDDEN_UNITS}\")\n",
    "print(f\"Train threshold: {TRAINING_THRESHOLD}\")\n",
    "print(f\"Epochs: {EPOCHS} learning_rate: {LEARNING_RATE}\")\n",
    "print(f\"Optimizer: {optimizer.__class__.__name__} Scheduler: {scheduler.__class__.__name__}\")\n",
    "\n",
    "print(\"--Results\")\n",
    "print(f\"Validation loss: {val_loss:.5f} Performance {PERFORMANCE_MEASURE}: {val_performance*100:.2f}%\")\n",
    "print(f\"Train validation confusion matrix:\\n{confmat_tensor}\")\n",
    "print(f\"Train validation accuracy: {val_accuracy*100:.2f}%\")\n",
    "print(f\"Train validation precision: {val_precision*100:.2f}%\")\n",
    "print(f\"Train validation false_positives: {false_positives} true_positives: {true_positives}\")\n",
    "\n",
    "print(f\"Trained model: {MODEL_NAME}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5afa50f8-6e03-45fd-8f74-6f47da208d13",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "  import torchinfo\n",
    "except:\n",
    "  !pip install torchinfo\n",
    "  import torchinfo\n",
    "\n",
    "from torchinfo import summary  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5025345-72b4-4170-90c8-307279d139ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary(model_0, input_size=[len(signal_avg)])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
