{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# Model Training\n",
    "Trains a model on past data using multiple tickers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import settings\n",
    "import apis.tiingo_api as tiingo\n",
    "\n",
    "secret_key= settings.get_secret(\"tiingo-key\")\n",
    "client = tiingo.TiingoAPI(secret_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_data2020= client.download_ticker(TICKER, datetime(2020, 1, 1), datetime(2021,1,1), 15, False)\n",
    "csv_data2021= client.download_ticker(TICKER, datetime(2021, 1, 1), datetime(2022,1,1), 15, False)\n",
    "csv_data2022= client.download_ticker(TICKER, datetime(2022, 1, 1), datetime(2023,1,1), 15, False)\n",
    "csv_data2023= client.download_ticker(TICKER, datetime(2023, 1, 1), datetime(2023,11,11), 15, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate list skipping the header row\n",
    "#csv_data=csv_data2020+ \"\\n\" + csv_data2021[1:-1]+ \"\\n\" + csv_data2022[1:-1]+ \"\\n\" + csv_data2023[1:-1]\n",
    "#len(csv_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "import pandas as pd\n",
    "\n",
    "df2020 = pd.read_csv(io.StringIO(csv_data2020))\n",
    "df2021 = pd.read_csv(io.StringIO(csv_data2021))\n",
    "df2022 = pd.read_csv(io.StringIO(csv_data2022))\n",
    "df2023 = pd.read_csv(io.StringIO(csv_data2023))\n",
    "df = pd.concat([df2020, df2021, df2022, df2023], axis=0, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "close_list = df['close'].astype(float).tolist()\n",
    "close_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "classes_window= 52\n",
    "down_pcts= [7]\n",
    "up_pcts= [7]\n",
    "calculator = classes_calc.ClassesCalc(classes_calc.find_first_up_down, classes_window, down_pcts, up_pcts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "classes= calculator.calculate(close_list)\n",
    "print(classes[-classes_window-1:-classes_window+1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Create a histogram\n",
    "hist_values, bin_edges, _ = plt.hist(classes, bins=21, edgecolor='black')\n",
    "\n",
    "# Add labels and a title\n",
    "plt.xlabel('Value')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Histogram of Data')\n",
    "\n",
    "# Display frequency on top of each bar\n",
    "for value, edge in zip(hist_values, bin_edges[:-1]):\n",
    "    plt.text(edge + 0.5, value + 0.1, str(int(value)), color='black')\n",
    "    \n",
    "# Show the histogram\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "# Calculate the frequency of each element\n",
    "frequency_dict = Counter(classes)\n",
    "\n",
    "# Print the result\n",
    "num_ticks= len(classes)\n",
    "print(f\"Stock ticks: {num_ticks}\")\n",
    "for element, frequency in frequency_dict.items():\n",
    "    percent=0\n",
    "    position= element - len(down_pcts)\n",
    "    if position < 0:\n",
    "        percent= -1 * down_pcts[-1 * position - 1] \n",
    "    elif position > 0:\n",
    "        percent= up_pcts[position - 1]\n",
    "        \n",
    "    print(f\"{percent}% change ({element}): {frequency} times {(frequency/num_ticks*100):0.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "\n",
    "import signals_calc\n",
    "\n",
    "# Reload the module when changes are made\n",
    "importlib.reload(signals_calc)\n",
    "\n",
    "signal_windows= [2, 3, 5, 8, 13, 21, 34, 55, 89, 144, 233, 377, 610, 987, 1597, 2584]\n",
    "signals_calculator = signals_calc.SignalsCalc(signal_windows)\n",
    "\n",
    "windows_rolling_avg = signals_calculator.calculate(close_list)\n",
    "windows_rolling_avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(close_list))\n",
    "print(len(windows_rolling_avg[len(signal_windows)-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "from src.classificators.proportions_calc import calculate_proportions\n",
    "\n",
    "\n",
    "proportions= calculate_proportions(close_list, windows_rolling_avg)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(close_list[-10:])\n",
    "print(windows_rolling_avg[0][-10:])\n",
    "print(proportions[0][-10:])\n",
    "current_sum = sum(close_list[-2:])/2\n",
    "classes_len= len(classes)\n",
    "signal_windows_len= len(signal_windows)\n",
    "\n",
    "print(f\"Signal window last: {signal_windows[-1]} len: {signal_windows_len}\")\n",
    "print(f\"Classes last non-nan: {classes[-classes_window-1:-classes_window+1]} len: {classes_len}\")\n",
    "print(f\"Proportions first non-nan: {proportions[signal_windows_len-1][signal_windows[-1]-2:signal_windows[-1]]} len: {len(proportions[signal_windows_len-1])}\")\n",
    "print(f\"Proportions {signal_windows[0]} Min: {min(proportions[0][signal_windows[0]-1:-classes_window-1])} Max: {max(proportions[0][signal_windows[0]-1:-classes_window])}\")\n",
    "print(f\"Proportions {signal_windows[-1]} Min: {min(proportions[-1][signal_windows[-1]-1:-classes_window-1])} Max: {max(proportions[-1][signal_windows[-1]-1:-classes_window])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cutting from first non-nan in the signal_windows[-1] to last non-nan in the classes\n",
    "targets = classes[signal_windows[-1]-1:-classes_window]\n",
    "print(f\"First target: {targets[0]} and last target: {targets[-1]}\")\n",
    "print(f\"Classes: {len(classes)} cut to targets: {len(targets)}\")\n",
    "inputs = []\n",
    "for proportion in proportions:\n",
    "    proportion_cut=proportion[signal_windows[-1]-1:-classes_window]\n",
    "    print(proportion_cut[0:2])\n",
    "    inputs.append(proportion_cut)\n",
    "    \n",
    "print(f\"Inputs {len(inputs[len(signal_windows)-1])}\")\n",
    "print(f\"Distinct targets: {list(set(targets))}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# TODO: Only 4 decimals in the X values, should not be more? How to increase?\n",
    "X = torch.Tensor(inputs)\n",
    "X = X.T\n",
    "y = torch.Tensor(targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_split= int(0.8 * len(X))\n",
    "X_train, y_train= X[:train_split], y[:train_split]\n",
    "X_test, y_test= X[train_split:], y[train_split:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"X_train shape: {X_train.shape} y_train shape: {y_train.shape}\")\n",
    "print(f\"X_test shape: {X_test.shape} y_test shape: {y_test.shape}\")\n",
    "print(f\"X_train: {X_train}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "X_train, y_train= X_train.to(device), y_train.to(device).to(torch.int64)\n",
    "X_test, y_test= X_test.to(device), y_test.to(device).to(torch.int64)\n",
    "\n",
    "print(f\"X_train shape: {X_train.shape} type: {X_train.dtype} y_train shape: {y_train.shape} type: {y_train.dtype}\")\n",
    "print(f\"X_test shape: {X_test.shape} y_test shape: {y_test.shape}\")\n",
    "print(f\"X_train: {X_train}\")\n",
    "print(f\"y_train: {y_train}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "class StockModelV0(nn.Module):\n",
    "  def __init__(self, input_features, output_features, hidden_units):\n",
    "    \"\"\"Initializes multi-class classification model\"\"\"\n",
    "    super().__init__()\n",
    "    self.linear_layer_stack = nn.Sequential(\n",
    "      nn.Linear(in_features=input_features, out_features=hidden_units*3),\n",
    "      nn.ReLU(),\n",
    "      nn.Linear(in_features=hidden_units*3, out_features=hidden_units*2),\n",
    "      nn.ReLU(),\n",
    "      nn.Linear(in_features=hidden_units*2, out_features=hidden_units),\n",
    "      nn.ReLU(),\n",
    "      nn.Linear(in_features=hidden_units, out_features=output_features)\n",
    "    )\n",
    "\n",
    "  def forward(self, x):\n",
    "    # print(\"forward x: \",\", \".join([str(num) for num in x.tolist()]))\n",
    "    # Layers are defined inside the Sequencial NN and will be applied here.\n",
    "    return self.linear_layer_stack(x)\n",
    "\n",
    "# Create an instance of the model\n",
    "model_0 = StockModelV0(\n",
    "  input_features=len(signal_windows),\n",
    "  output_features=len(down_pcts)+ 1 + len(up_pcts),\n",
    "  hidden_units=10).to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchmetrics import Accuracy\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(params=model_0.parameters(), lr=0.5)\n",
    "accuracy_fn= Accuracy(task='multiclass', num_classes=len(down_pcts)+ 1 + len(up_pcts)).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"y_train: {y_train}\")\n",
    "print(f\"y_train.dtype: {y_train.dtype}\")\n",
    "model_0.eval()\n",
    "with torch.inference_mode():\n",
    "    y_logits= model_0(X_train)\n",
    "    print(y_logits)\n",
    "    y_pred= torch.argmax(torch.softmax(y_logits, dim=1), dim=1)\n",
    "    print(f\"y_pred: \", \", \".join([str(num) for num in y_pred.tolist()]))\n",
    "    print(f\"y_pred.dtype: {y_pred.dtype}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs=10000\n",
    "\n",
    "for epoch in range(epochs):\n",
    "  # Training\n",
    "  model_0.train()\n",
    "\n",
    "  # Forward pass\n",
    "  y_logits= model_0(X_train)\n",
    "    \n",
    "  # turn logits -> prediction probabilities -> prediction labels\n",
    "  y_pred= torch.argmax(torch.softmax(y_logits, dim=1), dim=1)\n",
    "  \n",
    "  # Calculate loss and accuracy\n",
    "  loss= loss_fn(y_logits, y_train)\n",
    "  accuracy = accuracy_fn(y_pred, y_train)\n",
    "    \n",
    "  # Optimize zero grad\n",
    "  optimizer.zero_grad()\n",
    "\n",
    "  # Backpropagation\n",
    "  loss.backward()\n",
    "\n",
    "  # Gradient descent optimization\n",
    "  optimizer.step()\n",
    "\n",
    "  model_0.eval()\n",
    "  with torch.inference_mode():\n",
    "    # Predict for test data\n",
    "    test_logits= model_0(X_test)\n",
    "    test_pred= torch.argmax(torch.softmax(test_logits, dim=1), dim=1)\n",
    "\n",
    "    # Calculate test loss/accuracy\n",
    "    test_loss= loss_fn(test_logits, y_test)\n",
    "    test_accuracy = accuracy_fn(test_pred, y_test)\n",
    "\n",
    "    if epoch % 100 == 0: \n",
    "      print(f\"Epoch: {epoch} | Loss: {loss:.5f} Acc: {accuracy*100:.2f}% | Test loss: {test_loss:.5f} Test acc: {test_accuracy*100:.2f}%\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Distinct y_test: {list(set(y_test.tolist()))}\")\n",
    "print(f\"Distinct test_pred: {list(set(test_pred.tolist()))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchmetrics import ConfusionMatrix\n",
    "# plot_confusion_matrix will plot the metrix in a nicer way\n",
    "from mlxtend.plotting import plot_confusion_matrix\n",
    "\n",
    "confmat= ConfusionMatrix(\n",
    "  task='multiclass',\n",
    "  num_classes=len(down_pcts)+ 1 + len(up_pcts))\n",
    "\n",
    "# test_data.targets are the values we want to predict in the test dataloader\n",
    "confmat_tensor= confmat(\n",
    "  preds= test_pred.cpu(),\n",
    "  target= y_test.cpu())\n",
    "\n",
    "# Plot the confusion matrix\n",
    "fig, ax= plot_confusion_matrix(\n",
    "  conf_mat= confmat_tensor.numpy(),\n",
    "  figsize= (10, 7)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "  import torchinfo\n",
    "except:\n",
    "  !pip install torchinfo\n",
    "  import torchinfo\n",
    "\n",
    "from torchinfo import summary  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary(model_0, input_size=[len(signal_windows)])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
